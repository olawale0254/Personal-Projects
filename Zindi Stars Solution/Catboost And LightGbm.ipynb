{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bqWnNjTaiB4E"
   },
   "source": [
    "# Uber Movement Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6OvbHhciB4Q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pandas_profiling as pf \n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from tqdm import tqdm\n",
    "#tqdm.pandas()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "%matplotlib inline\n",
    "# !pip install pandas_profiling\n",
    "\n",
    "import gc\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier,Pool,cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Bad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.rename(columns = {'Occurrence Local Date Time':'Datetime'})\n",
    "train=train.rename(columns = {'road_segment_id':'segment_id'})\n",
    "\n",
    "### Date conversion (make dayfirst=True)\n",
    "train['Datetime'] = pd.to_datetime(train['Datetime'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_seg = ['-34.0436786939','-33.9622761744','-33.8891283413','-34.0894652753','-33.9680008638']\n",
    "for seg in bad_seg:\n",
    "    train.loc[train['segment_id'] == seg , 'longitude']  = train.loc[train['segment_id'] == seg , 'latitude']\n",
    "    train.loc[train['segment_id'] == seg , 'latitude']  = train.loc[train['segment_id'] == seg , 'segment_id']\n",
    "    train.loc[train['segment_id'] == seg , 'segment_id']  = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Reporting Agency</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Subcause</th>\n",
       "      <th>Status</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>segment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16693</td>\n",
       "      <td>88632</td>\n",
       "      <td>2016-12-09 04:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cam</td>\n",
       "      <td>Accident</td>\n",
       "      <td>Single Vehicle</td>\n",
       "      <td>18.5642</td>\n",
       "      <td>-33.9622761744</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23455</td>\n",
       "      <td>100642</td>\n",
       "      <td>2017-05-16 07:22:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cdam</td>\n",
       "      <td>Congestion</td>\n",
       "      <td>Any</td>\n",
       "      <td>18.8397</td>\n",
       "      <td>-34.0894652753</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23747</td>\n",
       "      <td>101150</td>\n",
       "      <td>2017-05-21 08:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cam</td>\n",
       "      <td>Routine Road Maintenance</td>\n",
       "      <td>Any</td>\n",
       "      <td>18.5798</td>\n",
       "      <td>-33.9680008638</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27586</td>\n",
       "      <td>108150</td>\n",
       "      <td>2017-08-30 07:12:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cam</td>\n",
       "      <td>Congestion</td>\n",
       "      <td>Any</td>\n",
       "      <td>18.6146</td>\n",
       "      <td>-33.8891283413</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30341</td>\n",
       "      <td>112789</td>\n",
       "      <td>2017-10-21 08:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cam</td>\n",
       "      <td>Stationary Vehicle</td>\n",
       "      <td>Vehicle On Shoulder</td>\n",
       "      <td>18.7424</td>\n",
       "      <td>-34.0436786939</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EventId            Datetime Reporting Agency Cause  \\\n",
       "16693    88632 2016-12-09 04:45:00              NaN   Cam   \n",
       "23455   100642 2017-05-16 07:22:00              NaN  cdam   \n",
       "23747   101150 2017-05-21 08:30:00              NaN   cam   \n",
       "27586   108150 2017-08-30 07:12:00              NaN   cam   \n",
       "30341   112789 2017-10-21 08:03:00              NaN   cam   \n",
       "\n",
       "                       Subcause               Status longitude  \\\n",
       "16693                  Accident       Single Vehicle   18.5642   \n",
       "23455                Congestion                  Any   18.8397   \n",
       "23747  Routine Road Maintenance                  Any   18.5798   \n",
       "27586                Congestion                  Any   18.6146   \n",
       "30341        Stationary Vehicle  Vehicle On Shoulder   18.7424   \n",
       "\n",
       "             latitude segment_id  \n",
       "16693  -33.9622761744        NaN  \n",
       "23455  -34.0894652753        NaN  \n",
       "23747  -33.9680008638        NaN  \n",
       "27586  -33.8891283413        NaN  \n",
       "30341  -34.0436786939        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.segment_id.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['EventId'] == 88632, 'segment_id']   = '6OTRJQF'\n",
    "train.loc[train['EventId'] == 100642, 'segment_id']   = 'Q03FQ74'\n",
    "train.loc[train['EventId'] == 101150, 'segment_id']   = 'S2QPOTD'\n",
    "train.loc[train['EventId'] == 108150, 'segment_id']   = 'LNO3W8J'\n",
    "train.loc[train['EventId'] == 112789, 'segment_id']   = 'IUTMY1U'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Reporting Agency</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Subcause</th>\n",
       "      <th>Status</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>segment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [EventId, Datetime, Reporting Agency, Cause, Subcause, Status, longitude, latitude, segment_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.segment_id.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accident Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accident = train.segment_id.value_counts().reset_index().rename(columns = {'index':'Road_Segment',\n",
    "                                                                    'segment_id':'Accident'})\n",
    "Accident['Accident'] = Accident['Accident'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accident_Per_SegmentId.csv  seg_Length.csv            seg_pavement_v2.csv\r\n",
      "Add_feat_cause.csv          seg_Length_v2.csv         seg_roadtype.csv\r\n",
      "GeoData_001to1107.csv       SegmentId_and_suburb.csv  seg_roadtype_v2.csv\r\n",
      "GeoData_1107tolast.csv      segment_id_suburb_v2.csv  train.csv\r\n",
      "\u001b[0m\u001b[01;34mroad_segments\u001b[0m/              seg_pavement.csv          weather.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Zv2JNPLiB4m"
   },
   "outputs": [],
   "source": [
    "# test = pd.read_csv('Data/SampleSubmission.csv',error_bad_lines=False)\n",
    "# Suburb = pd.read_csv(\"Data/segment_id_suburb_v2.csv\")\n",
    "Suburb = pd.read_csv(\"Data/SegmentId_and_suburb.csv\")\n",
    "road_type = pd.read_csv(\"Data/seg_roadtype_v2.csv\")\n",
    "road_pavement = pd.read_csv(\"Data/seg_pavement_v2.csv\")\n",
    "road_Length = pd.read_csv(\"Data/seg_Length_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Reporting Agency</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Subcause</th>\n",
       "      <th>Status</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>segment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60558</td>\n",
       "      <td>2016-01-01 00:53:00</td>\n",
       "      <td>Cam</td>\n",
       "      <td>Stationary Vehicle</td>\n",
       "      <td>Vehicle On Shoulder</td>\n",
       "      <td>Closed</td>\n",
       "      <td>18.5408955032</td>\n",
       "      <td>-33.8883</td>\n",
       "      <td>S0B3CGQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>60559</td>\n",
       "      <td>2016-01-01 00:54:00</td>\n",
       "      <td>CAMERA</td>\n",
       "      <td>Accident</td>\n",
       "      <td>With A Fixed Object</td>\n",
       "      <td>Closed</td>\n",
       "      <td>18.9307563219</td>\n",
       "      <td>-34.1409</td>\n",
       "      <td>RYJYAPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60560</td>\n",
       "      <td>2016-01-01 02:26:00</td>\n",
       "      <td>Law Enforcement</td>\n",
       "      <td>Accident</td>\n",
       "      <td>Multi Vehicle</td>\n",
       "      <td>Closed</td>\n",
       "      <td>18.5533575029</td>\n",
       "      <td>-33.9592</td>\n",
       "      <td>U3KP57C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>60561</td>\n",
       "      <td>2016-01-01 02:56:00</td>\n",
       "      <td>CAMERA</td>\n",
       "      <td>Stationary Vehicle</td>\n",
       "      <td>Vehicle On Shoulder</td>\n",
       "      <td>Closed</td>\n",
       "      <td>18.6775561589</td>\n",
       "      <td>-33.8953</td>\n",
       "      <td>RY0TRQ8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60562</td>\n",
       "      <td>2016-01-01 03:40:00</td>\n",
       "      <td>CAMERA</td>\n",
       "      <td>Accident</td>\n",
       "      <td>Multi Vehicle</td>\n",
       "      <td>Closed</td>\n",
       "      <td>18.8371319682</td>\n",
       "      <td>-34.0871</td>\n",
       "      <td>8LOVJZ3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventId            Datetime Reporting Agency               Cause  \\\n",
       "0    60558 2016-01-01 00:53:00              Cam  Stationary Vehicle   \n",
       "1    60559 2016-01-01 00:54:00           CAMERA            Accident   \n",
       "2    60560 2016-01-01 02:26:00  Law Enforcement            Accident   \n",
       "3    60561 2016-01-01 02:56:00           CAMERA  Stationary Vehicle   \n",
       "4    60562 2016-01-01 03:40:00           CAMERA            Accident   \n",
       "\n",
       "              Subcause  Status      longitude latitude segment_id  \n",
       "0  Vehicle On Shoulder  Closed  18.5408955032 -33.8883    S0B3CGQ  \n",
       "1  With A Fixed Object  Closed  18.9307563219 -34.1409    RYJYAPI  \n",
       "2        Multi Vehicle  Closed  18.5533575029 -33.9592    U3KP57C  \n",
       "3  Vehicle On Shoulder  Closed  18.6775561589 -33.8953    RY0TRQ8  \n",
       "4        Multi Vehicle  Closed  18.8371319682 -34.0871    8LOVJZ3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pd.read_csv('Data/weather.csv', sep=\";\", skiprows=6, usecols=range(14),\n",
    "               parse_dates=['Local time in Cape Town (airport)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local time in Cape Town (airport)</th>\n",
       "      <th>T</th>\n",
       "      <th>P0</th>\n",
       "      <th>P</th>\n",
       "      <th>U</th>\n",
       "      <th>DD</th>\n",
       "      <th>Ff</th>\n",
       "      <th>ff10</th>\n",
       "      <th>WW</th>\n",
       "      <th>W'W'</th>\n",
       "      <th>c</th>\n",
       "      <th>VV</th>\n",
       "      <th>Td</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-04 23:00:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>765.8</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Wind blowing from the south-southeast</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scattered clouds (40-50%) 720 m, broken clouds...</td>\n",
       "      <td>10.0 and more</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-04 22:00:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>761.2</td>\n",
       "      <td>765.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Wind blowing from the south-southeast</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scattered clouds (40-50%) 570 m, broken clouds...</td>\n",
       "      <td>10.0 and more</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-04 21:59:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>761.2</td>\n",
       "      <td>765.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Wind blowing from the south-southeast</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scattered clouds (40-50%) 570 m, broken clouds...</td>\n",
       "      <td>10.0 and more</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-04 21:01:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>761.2</td>\n",
       "      <td>765.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Wind blowing from the south-southeast</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scattered clouds (40-50%) 150 m, broken clouds...</td>\n",
       "      <td>10.0 and more</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-04 21:00:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>761.2</td>\n",
       "      <td>765.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Wind blowing from the south-southeast</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scattered clouds (40-50%) 150 m, broken clouds...</td>\n",
       "      <td>10.0 and more</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Local time in Cape Town (airport)     T     P0      P     U  \\\n",
       "0               2019-04-04 23:00:00  15.0  762.0  765.8  77.0   \n",
       "1               2019-04-04 22:00:00  16.0  761.2  765.0  77.0   \n",
       "2               2019-04-04 21:59:00  16.0  761.2  765.0  77.0   \n",
       "3               2019-04-04 21:01:00  15.0  761.2  765.0  94.0   \n",
       "4               2019-04-04 21:00:00  15.0  761.2  765.0  94.0   \n",
       "\n",
       "                                      DD   Ff  ff10   WW W'W'  \\\n",
       "0  Wind blowing from the south-southeast  6.0   NaN  NaN  NaN   \n",
       "1  Wind blowing from the south-southeast  6.0   NaN  NaN  NaN   \n",
       "2  Wind blowing from the south-southeast  6.0   NaN  NaN  NaN   \n",
       "3  Wind blowing from the south-southeast  6.0   NaN  NaN  NaN   \n",
       "4  Wind blowing from the south-southeast  6.0   NaN  NaN  NaN   \n",
       "\n",
       "                                                   c             VV    Td  \\\n",
       "0  Scattered clouds (40-50%) 720 m, broken clouds...  10.0 and more  11.0   \n",
       "1  Scattered clouds (40-50%) 570 m, broken clouds...  10.0 and more  12.0   \n",
       "2  Scattered clouds (40-50%) 570 m, broken clouds...  10.0 and more  12.0   \n",
       "3  Scattered clouds (40-50%) 150 m, broken clouds...  10.0 and more  14.0   \n",
       "4  Scattered clouds (40-50%) 150 m, broken clouds...  10.0 and more  14.0   \n",
       "\n",
       "   Unnamed: 13  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w['dt'] = w['Local time in Cape Town (airport)'].dt.round('H')\n",
    "w['dt_2'] = w['Local time in Cape Town (airport)'].dt.floor('H')\n",
    "\n",
    "w_cols = ['dt','dt_2', 'T', 'P0', 'P', 'U', 'Ff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMjZM8t1iB6S"
   },
   "source": [
    "### Get Extra Feature from Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "OoFBUkuniB6d",
    "outputId": "029e3d48-5618-4693-e4fa-aa29f6dca094",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Count of occurance of incident\n",
    "Seg_Group = train.groupby(['segment_id','Datetime']).size().reset_index(name='Counts')\n",
    "\n",
    "### Mapping the Segment_id - from text to number\n",
    "LE = LabelEncoder()\n",
    "Seg_Group['segmentid_num'] = LE.fit_transform(Seg_Group['segment_id'])\n",
    "\n",
    "# Make all 3 digits of segments\n",
    "Seg_Group['segmentid_num3'] = [str(x).zfill(3) for x in Seg_Group['segmentid_num']]\n",
    "\n",
    "# Add 'seg_' to 3digit segment_id\n",
    "Seg_Group['segment_idx'] = 'seg_'+Seg_Group.segmentid_num3.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "ThkbD05QiB7O",
    "outputId": "c65c690f-20a0-443b-ad32-6f24d67232e1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Counts</th>\n",
       "      <th>segmentid_num</th>\n",
       "      <th>segmentid_num3</th>\n",
       "      <th>segment_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>03RHJ3G</td>\n",
       "      <td>2016-01-01 09:02:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>seg_000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>03RHJ3G</td>\n",
       "      <td>2016-01-04 09:46:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>seg_000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>03RHJ3G</td>\n",
       "      <td>2016-01-04 13:29:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>seg_000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>03RHJ3G</td>\n",
       "      <td>2016-01-05 14:41:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>seg_000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>03RHJ3G</td>\n",
       "      <td>2016-01-05 16:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>seg_000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  segment_id            Datetime  Counts  segmentid_num segmentid_num3  \\\n",
       "0    03RHJ3G 2016-01-01 09:02:00       1              0            000   \n",
       "1    03RHJ3G 2016-01-04 09:46:00       1              0            000   \n",
       "2    03RHJ3G 2016-01-04 13:29:00       1              0            000   \n",
       "3    03RHJ3G 2016-01-05 14:41:00       1              0            000   \n",
       "4    03RHJ3G 2016-01-05 16:10:00       1              0            000   \n",
       "\n",
       "  segment_idx  \n",
       "0     seg_000  \n",
       "1     seg_000  \n",
       "2     seg_000  \n",
       "3     seg_000  \n",
       "4     seg_000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Seg_Group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oij26HaJiB75"
   },
   "source": [
    "### Extract unique Segment Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IynYqQaGiB8D",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "## Drop duplicate segment_id\n",
    "SegIdQ = Seg_Group[['segment_id','segment_idx','segmentid_num']].drop_duplicates()\n",
    "# segment_id_1\n",
    "SegIdQx = SegIdQ['segment_id'].unique()\n",
    "# segmen_id_2\n",
    "SegIdQx2 = SegIdQ['segment_idx'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add centre of Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.longitude = train.longitude.astype(float)\n",
    "train.latitude = train.latitude.astype(float)\n",
    "\n",
    "## Get centre location of the segment\n",
    "location =  train.groupby('segment_id').median()[['longitude', 'latitude']]\n",
    "SegIdQ = SegIdQ.merge(location, left_on=['segment_id'], how=\"left\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>segment_idx</th>\n",
       "      <th>segmentid_num</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>03RHJ3G</td>\n",
       "      <td>seg_000</td>\n",
       "      <td>0</td>\n",
       "      <td>18.459897</td>\n",
       "      <td>-33.943257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582</td>\n",
       "      <td>044ZYVD</td>\n",
       "      <td>seg_001</td>\n",
       "      <td>1</td>\n",
       "      <td>18.554505</td>\n",
       "      <td>-33.890213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613</td>\n",
       "      <td>086LLYS</td>\n",
       "      <td>seg_002</td>\n",
       "      <td>2</td>\n",
       "      <td>18.432873</td>\n",
       "      <td>-33.918816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>637</td>\n",
       "      <td>0B0QOEN</td>\n",
       "      <td>seg_003</td>\n",
       "      <td>3</td>\n",
       "      <td>18.477737</td>\n",
       "      <td>-33.917932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0F3OY57</td>\n",
       "      <td>seg_004</td>\n",
       "      <td>4</td>\n",
       "      <td>18.773261</td>\n",
       "      <td>-34.057950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    segment_id segment_idx  segmentid_num  longitude   latitude\n",
       "0      03RHJ3G     seg_000              0  18.459897 -33.943257\n",
       "582    044ZYVD     seg_001              1  18.554505 -33.890213\n",
       "613    086LLYS     seg_002              2  18.432873 -33.918816\n",
       "637    0B0QOEN     seg_003              3  18.477737 -33.917932\n",
       "790    0F3OY57     seg_004              4  18.773261 -34.057950"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SegIdQ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add other segment related feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add centre Accident_count to data_set\n",
    "SegIdQ = pd.merge(SegIdQ, Accident[['Road_Segment','Accident']], left_on='segment_id', right_on='Road_Segment', how='left') # Segment locations\n",
    "SegIdQ = pd.merge(SegIdQ, Suburb[['segment_id','suburb']], left_on='segment_id', right_on='segment_id', how='left') # Segment locations\n",
    "# SegIdQ = pd.merge(SegIdQ, Cause, left_on='segment_id', right_on='Road_Segment', how='left') # Segment locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add centre Other  to data_set\n",
    "SegIdQ = pd.merge(SegIdQ, road_Length, left_on='segment_id', right_on='segment_id', how='left') # Segment locations\n",
    "SegIdQ = pd.merge(SegIdQ, road_type, left_on='segment_id', right_on='segment_id', how='left') # Segment locations\n",
    "SegIdQ = pd.merge(SegIdQ, road_pavement, left_on='segment_id', right_on='segment_id', how='left') # Segment locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7erKy03niB8K"
   },
   "source": [
    "### Merging Train Dataset with Segment Features from NoteBook(`Geo-Spatial Features Extraction_v3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "-qZWFboMiB8N",
    "outputId": "24cddb12-806e-4c2d-db0b-052ca8533fa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train # B4 merging 53845\n",
      "Train # After merging 53845\n"
     ]
    }
   ],
   "source": [
    "trainX = pd.merge(train, SegIdQ, on=['segment_id'], how=\"left\")\n",
    "print('Train # B4 merging',len(train))\n",
    "print('Train # After merging',len(trainX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dI08znjyiB8V"
   },
   "outputs": [],
   "source": [
    "# del SegIdQ\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX.to_csv('train_transformed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdOe5-sXiB8n"
   },
   "source": [
    "### CreateTrain Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get day not in Train day and save as missing_days\n",
    "Main_day = pd.date_range('2016-01-01','2018-12-31',\n",
    "                           freq=\"1D\")\n",
    "Main_day = pd.DataFrame({'datetime':Main_day.date})\n",
    "\n",
    "train_days = trainX['Datetime'].dt.date.drop_duplicates()\n",
    "missing_days = Main_day[~Main_day['datetime'].isin(train_days)]\n",
    "\n",
    "del train_days, Main_day\n",
    "missing_days['datetime'] = pd.to_datetime(missing_days.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "iYiyXox5iB8p",
    "outputId": "824afd44-8577-4815-bdfe-9ab3260c34d6"
   },
   "outputs": [],
   "source": [
    "Data1Hour = pd.date_range('2016-01-01',\n",
    "                          '2018-12-31 23:00:00',\n",
    "                           freq=\"1h\")\n",
    "Data1Hour = pd.DataFrame({'datetime':Data1Hour})\n",
    "###Remove missing date from date range\n",
    "Data1Hour = Data1Hour[~Data1Hour['datetime'].dt.date.isin(missing_days['datetime'].dt.date)]\n",
    "\n",
    "# Generate Target\n",
    "for SegId in SegIdQx2:\n",
    "    Data1Hour[str(SegId)] = 0\n",
    "    events = trainX.loc[trainX['segment_idx'] == SegId]\n",
    "    dts = events['Datetime'].dt.floor('H')\n",
    "    dates = dts.astype(str).unique()\n",
    "    Data1Hour.loc[Data1Hour['datetime'].isin(dates), SegId] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24672, 545)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1Hour.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "UOHIPI-JiB9H",
    "outputId": "6786e5c9-d56c-49c2-ee69-8a60092e4c70"
   },
   "outputs": [],
   "source": [
    "test1Hour = pd.date_range('2019-01-01 01:00:00',\n",
    "                          '2019-03-31 23:00:00' ,\n",
    "                           freq=\"1h\")\n",
    "\n",
    "test1Hour = pd.DataFrame({'datetime':test1Hour})\n",
    "\n",
    "# Generate Target\n",
    "for SegId in SegIdQx2:\n",
    "    test1Hour[str(SegId)] = np.NAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1Hour.set_index('datetime', inplace=True)\n",
    "Data1Hour.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert seg to Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1Hour = Data1Hour.reset_index()\n",
    "test1Hour = test1Hour.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1Hour = pd.melt(Data1Hour, id_vars=['datetime'])\n",
    "Data1Hour.rename(columns={'variable': 'seg', 'value': 'target'}, inplace=True)\n",
    "Data1Hour['seg'] = Data1Hour.seg.map(lambda x: int(x[4:]))\n",
    "Data1Hour.set_index('datetime', inplace=True)\n",
    "# Data1Hour.sort_values('datetime', inplace=True)\n",
    "Data1Hour = Data1Hour.sort_values('datetime')\n",
    "\n",
    "\n",
    "\n",
    "test1Hour = pd.melt(test1Hour, id_vars=['datetime'])\n",
    "test1Hour.rename(columns={'variable': 'seg', 'value': 'target'}, inplace=True)\n",
    "test1Hour['seg'] = test1Hour.seg.map(lambda x: int(x[4:]))\n",
    "test1Hour.set_index('datetime', inplace=True)\n",
    "\n",
    "test1Hour = test1Hour.sort_values('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            seg  target\n",
       "datetime               \n",
       "2016-01-01    0       0\n",
       "2016-01-01  170       0\n",
       "2016-01-01  171       0\n",
       "2016-01-01  172       0\n",
       "2016-01-01  173       0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1Hour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDHXa28iiB-n",
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "### Timebased FeatEngineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qJovrKQiB_K"
   },
   "outputs": [],
   "source": [
    "attr = [\"Hour\",\"Year\", 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear','quarter',\"weekday_name\",\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "\n",
    "for n in attr: \n",
    "    Data1Hour[n] = getattr(Data1Hour.index, n.lower())\n",
    "    test1Hour[n] = getattr(test1Hour.index, n.lower())\n",
    "\n",
    "# Data1Hour['Elapsed'] = Data1Hour.index.astype(np.int64) // 10 ** 9\n",
    "# test1Hour['Elapsed'] = test1Hour.index.astype(np.int64) // 10 ** 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hso32GVKiB_Q"
   },
   "outputs": [],
   "source": [
    "## WeekEnd\n",
    "Data1Hour['IsWeekend'] = np.where(Data1Hour['Dayofweek'] < 5,0,1)\n",
    "test1Hour['IsWeekend'] = np.where(test1Hour['Dayofweek'] < 5,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yPust2YgiB_n"
   },
   "outputs": [],
   "source": [
    "# Holiday \n",
    "from pandas.tseries.holiday import *\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "\n",
    "class SouthAfricaHoliday(AbstractHolidayCalendar):\n",
    "   rules = [\n",
    "     Holiday('New Year', month=1, day=1, observance=sunday_to_monday),\n",
    "     Holiday('Human Rights Day', month=3, day=21, observance=sunday_to_monday),\n",
    "     Holiday('Good Friday', month=1, day=1, offset=[Easter(), Day(-2)]),\n",
    "     Holiday('Easter Monday', month=1, day=1, offset=[Easter(), Day(1)]),\n",
    "     Holiday('Freedom Day', month=4, day=27, observance=sunday_to_monday),\n",
    "     Holiday('Workers Day', month=5, day=1,observance=sunday_to_monday),\n",
    "     Holiday('Youth Day', month=6, day=16, observance=sunday_to_monday),\n",
    "     Holiday('Womens Day', month=8, day=9, observance=sunday_to_monday),\n",
    "     Holiday('Heritage Day', month=9, day=24, observance=sunday_to_monday),\n",
    "     Holiday('Day of Reconcilation', month=12, day=16, observance=sunday_to_monday),\n",
    "     Holiday('Goodwill Day', month=12, day=26, observance=sunday_to_monday),\n",
    "     Holiday('Christmas', month=12, day=25)\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eCtAdcPkiB_5",
    "outputId": "fd680563-c6ba-4953-b60c-76b5263bf0d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2016-01-01 00:00:00'), Timestamp('2019-03-31 23:00:00'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1Hour.index.min(), test1Hour.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aC_xqwLuiCAD"
   },
   "outputs": [],
   "source": [
    "hol= SouthAfricaHoliday()\n",
    "myholidays =hol.holidays(start=Data1Hour.index.min(), end =test1Hour.index.max())\n",
    "hol_day = pd.Series(myholidays)\n",
    "\n",
    "### election\n",
    "election_day = \"2019-08-03\"\n",
    "hol_day = hol_day.append(pd.to_datetime(pd.Series([election_day])),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJmoE-RBiCAX"
   },
   "outputs": [],
   "source": [
    "## Create instance of holiday in a new column\n",
    "Data1Hour['IsHoliday'] = np.where((pd.to_datetime(Data1Hour.index.date)).isin(hol_day) ,1,0)\n",
    "test1Hour['IsHoliday'] = np.where((pd.to_datetime(test1Hour.index.date)).isin(hol_day) ,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_8CGfnkiCAg"
   },
   "outputs": [],
   "source": [
    "# pay_day \n",
    "\n",
    "Data1Hour['PayDay'] = np.where((Data1Hour['Day'] < 25) ,0,1)\n",
    "Data1Hour['PayDay_Teachers'] = np.where(Data1Hour['Day'] < 22,0,1)\n",
    "\n",
    "\n",
    "test1Hour['PayDay'] = np.where((test1Hour['Day'] < 25) ,0,1)\n",
    "test1Hour['PayDay_Teachers'] = np.where(test1Hour['Day'] < 22,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1Hour['min'] = Data1Hour.index.hour*60+Data1Hour.index.minute\n",
    "test1Hour['min'] = test1Hour.index.hour*60+test1Hour.index.minute\n",
    "\n",
    "Data1Hour['Hour_sin'] = np.sin(2 * np.pi * Data1Hour['Hour']/23.0)\n",
    "Data1Hour['Hour_cos'] = np.cos(2 * np.pi * Data1Hour['Hour']/23.0)\n",
    "\n",
    "test1Hour['Hour_sin'] = np.sin(2 * np.pi * test1Hour['Hour']/23.0)\n",
    "test1Hour['Hour_cos'] = np.cos(2 * np.pi * test1Hour['Hour']/23.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seg', 'target', 'Hour', 'Year', 'Month', 'Week', 'Day', 'Dayofweek',\n",
       "       'Dayofyear', 'quarter', 'weekday_name', 'Is_month_end',\n",
       "       'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end',\n",
       "       'Is_year_start', 'IsWeekend', 'IsHoliday', 'PayDay', 'PayDay_Teachers',\n",
       "       'min', 'Hour_sin', 'Hour_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1Hour.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13421568, 24)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1Hour.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.99617\n",
       "1    0.00383\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1Hour.target.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WF7eb72iCDd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bt1EEPc5VXQ4"
   },
   "outputs": [],
   "source": [
    "## Memory reduce Function\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKJmxyLVWLaI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2062.37 MB\n",
      "Memory usage after optimization is: 603.19 MB\n",
      "Decreased by 70.8%\n",
      "Memory usage of dataframe is 216.97 MB\n",
      "Memory usage after optimization is: 96.00 MB\n",
      "Decreased by 55.8%\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(Data1Hour)\n",
    "test = reduce_mem_usage(test1Hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyMemTfUiCD-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.99617\n",
       "1    0.00383\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values('datetime')\n",
    "test = test.sort_values('datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge New features to Train and Test DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seg', 'target', 'Hour', 'Year', 'Month', 'Week', 'Day', 'Dayofweek',\n",
       "       'Dayofyear', 'quarter', 'weekday_name', 'Is_month_end',\n",
       "       'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end',\n",
       "       'Is_year_start', 'IsWeekend', 'IsHoliday', 'PayDay', 'PayDay_Teachers',\n",
       "       'min', 'Hour_sin', 'Hour_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['datetime'] = test.index\n",
    "train['datetime'] = train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge Weather\n",
    "w = w[w_cols].drop_duplicates(['dt_2'])\n",
    "train = pd.merge(train, w[w_cols], left_index=True, right_on='dt_2', how='left') # Weather\n",
    "test = pd.merge(test, w[w_cols], left_index=True, right_on='dt_2', how='left') # Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge Other New feature Stored in SegIdQ\n",
    "train = pd.merge(train, SegIdQ, left_on=['seg'], right_on=['segmentid_num'], how=\"left\")\n",
    "test = pd.merge(test, SegIdQ, left_on=['seg'], right_on=['segmentid_num'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.set_index('datetime', inplace=True)\n",
    "train.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['datetime x segment_id'] = test.index.astype('str') + ' x ' + test['segment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13421568, 42), (1174496, 43))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seg', 'target', 'Hour', 'Year', 'Month', 'Week', 'Day', 'Dayofweek',\n",
       "       'Dayofyear', 'quarter', 'weekday_name', 'Is_month_end',\n",
       "       'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end',\n",
       "       'Is_year_start', 'IsWeekend', 'IsHoliday', 'PayDay', 'PayDay_Teachers',\n",
       "       'min', 'Hour_sin', 'Hour_cos', 'dt', 'dt_2', 'T', 'P0', 'P', 'U', 'Ff',\n",
       "       'segment_id', 'segment_idx', 'segmentid_num', 'longitude', 'latitude',\n",
       "       'Road_Segment', 'Accident', 'suburb', 'length_1', 'roadno', 'surftype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Columns to be deleted\n",
    "del_col = [\n",
    "       'Day', \n",
    "#          'Dayofweek', 'Hour', \n",
    "#          'Hour_cos', 'Hour_sin',\n",
    "#        'IsHoliday', 'IsWeekend', \n",
    "       'Is_month_end', 'Is_month_start',\n",
    "       'Is_quarter_end', 'Is_quarter_start', \n",
    "       'Is_year_end', 'Is_year_start',\n",
    "       'PayDay', \n",
    "       'PayDay_Teachers', \n",
    "       'Week', \n",
    "        'min',\n",
    "       'quarter', \n",
    "#        'seg',\n",
    "    'dt',\n",
    "     'dt_2',\n",
    "     'T',\n",
    "     'P0',\n",
    "     'P',\n",
    "     'U',\n",
    "     'Ff',\n",
    "#     'RoadNo',\n",
    "#     'SURFTYPE'\n",
    "      'Cause', 'Freq', 'CatNo_cause',\n",
    "#     'longitude', 'latitude',\n",
    "#     'Accident', 'suburb',\n",
    "      'weekday_name','Dayofyear',\n",
    "      'Road_Segment_x','segment_id','Road_Segment_y','Month', 'segmentid_num','segment_idx',       \n",
    "      'target','Year','SegmentId','SegmentId_x','SegmentId_y','Road_Segment'\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seg', 'target', 'Hour', 'Year', 'Month', 'Week', 'Day', 'Dayofweek',\n",
       "       'Dayofyear', 'quarter', 'weekday_name', 'Is_month_end',\n",
       "       'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end',\n",
       "       'Is_year_start', 'IsWeekend', 'IsHoliday', 'PayDay', 'PayDay_Teachers',\n",
       "       'min', 'Hour_sin', 'Hour_cos', 'dt', 'dt_2', 'T', 'P0', 'P', 'U', 'Ff',\n",
       "       'segment_id', 'segment_idx', 'segmentid_num', 'longitude', 'latitude',\n",
       "       'Road_Segment', 'Accident', 'suburb', 'length_1', 'roadno', 'surftype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify Cat col And Encode Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Hour','Dayofweek','seg','suburb','roadno','surftype']\n",
    "LE = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    train[col] = train[col].replace({np.nan:'NaN'})\n",
    "    train[col] = LE.fit_transform(train[col])\n",
    "    \n",
    "    test[col] = test[col].replace({np.nan:'NaN'})\n",
    "    test[col] =  LE.transform(test[col])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify TrainSet\n",
    "Train with only 2018 because it is the most recent  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4752384, 42), (1201152, 42))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start      = '2018-01-01'\n",
    "split_date = '2018-10-01'\n",
    "\n",
    "\n",
    "val_train = train[(train.index >= start) & (train.index <='2018-12-31 23:00:00')]\n",
    "val_test = train[train.index >= split_date]\n",
    "\n",
    "val_train.shape, val_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove August because it contains very few number of records\n",
    "val_train = val_train[~((val_train.index >= '2018-08-01') & (val_train.index <'2018-09-01'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_train Target value count \n",
      " 0    0.995385\n",
      "1    0.004615\n",
      "Name: target, dtype: float64\n",
      "Val_test Target value count \n",
      " 0    0.993427\n",
      "1    0.006573\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print ('Val_train Target value count \\n', val_train['target'].value_counts(True))\n",
    "print ('Val_test Target value count \\n', val_test['target'].value_counts(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seg',\n",
       " 'Hour',\n",
       " 'Dayofweek',\n",
       " 'IsWeekend',\n",
       " 'IsHoliday',\n",
       " 'Hour_sin',\n",
       " 'Hour_cos',\n",
       " 'longitude',\n",
       " 'latitude',\n",
       " 'Accident',\n",
       " 'suburb',\n",
       " 'length_1',\n",
       " 'roadno',\n",
       " 'surftype']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [x for x in train.columns if x not in del_col]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 373.16 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 120.24 MB\n",
      "Decreased by 67.8%\n",
      "Memory usage of dataframe is 103.10 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 33.22 MB\n",
      "Decreased by 67.8%\n"
     ]
    }
   ],
   "source": [
    "## Reduce training Features\n",
    "val_train[features] = reduce_mem_usage(val_train[features] )\n",
    "val_test[features] = reduce_mem_usage(val_test[features] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lgb Parametres\n",
    "\n",
    "lgb_params = {\n",
    "          \"booster\": \"gbtree\",\n",
    "          \"eta\": 0.05,\n",
    "         'num_iterations': 190,\n",
    "         'verbosity': 50,\n",
    "         'silent': 1,\n",
    "         'eval_metric': 'binary_logloss',\n",
    "         'seed': 2020,\n",
    "         'metric': 'binary_logloss',\n",
    "         \"max_depth\": 15,\n",
    "          'is_unbalance': True,\n",
    "          \"subsample\": 0.8,\n",
    "          \"colsample_bytree\": 0.8,\n",
    "          \"alpha\": 0.4\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "## Cat_boost Parametres\n",
    "cat_params= {\n",
    "            'num_boost_round': 250,\n",
    "            'use_best_model':True,\n",
    "            'depth': 8,\n",
    "            'random_state': 2020,\n",
    "            'eval_metric': 'AUC', \n",
    "            'loss_function': 'Logloss',\n",
    "            'verbose': True\n",
    "}\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOf score 0.13560956148808137\n"
     ]
    }
   ],
   "source": [
    "trn_data = lgb.Dataset(val_train[features], label=val_train['target'])\n",
    "clf = lgb.train(lgb_params, trn_data, 190)\n",
    "\n",
    "predictions_lgb = clf.predict(test[features])\n",
    "oof_lgb = clf.predict(val_train[features])\n",
    "print ('OOf score', f1_score(val_train['target'], (oof_lgb > 0.05).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0.13560956148808137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier,Pool,cv,CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.458621\n",
      "0:\ttest: 0.7869819\tbest: 0.7869819 (0)\ttotal: 3.93s\tremaining: 16m 19s\n",
      "1:\ttest: 0.8344682\tbest: 0.8344682 (1)\ttotal: 7.49s\tremaining: 15m 28s\n",
      "2:\ttest: 0.8383004\tbest: 0.8383004 (2)\ttotal: 11.1s\tremaining: 15m 16s\n",
      "3:\ttest: 0.8454366\tbest: 0.8454366 (3)\ttotal: 14.4s\tremaining: 14m 45s\n",
      "4:\ttest: 0.8493965\tbest: 0.8493965 (4)\ttotal: 17.8s\tremaining: 14m 32s\n",
      "5:\ttest: 0.8572704\tbest: 0.8572704 (5)\ttotal: 21.1s\tremaining: 14m 16s\n",
      "6:\ttest: 0.8579470\tbest: 0.8579470 (6)\ttotal: 24.6s\tremaining: 14m 14s\n",
      "7:\ttest: 0.8581947\tbest: 0.8581947 (7)\ttotal: 27.9s\tremaining: 14m 3s\n",
      "8:\ttest: 0.8613665\tbest: 0.8613665 (8)\ttotal: 31.1s\tremaining: 13m 53s\n",
      "9:\ttest: 0.8623325\tbest: 0.8623325 (9)\ttotal: 34.7s\tremaining: 13m 52s\n",
      "10:\ttest: 0.8647969\tbest: 0.8647969 (10)\ttotal: 38.3s\tremaining: 13m 51s\n",
      "11:\ttest: 0.8652300\tbest: 0.8652300 (11)\ttotal: 41.8s\tremaining: 13m 48s\n",
      "12:\ttest: 0.8653167\tbest: 0.8653167 (12)\ttotal: 44.9s\tremaining: 13m 39s\n",
      "13:\ttest: 0.8659064\tbest: 0.8659064 (13)\ttotal: 48.2s\tremaining: 13m 32s\n",
      "14:\ttest: 0.8667945\tbest: 0.8667945 (14)\ttotal: 51.5s\tremaining: 13m 27s\n",
      "15:\ttest: 0.8670241\tbest: 0.8670241 (15)\ttotal: 55.1s\tremaining: 13m 25s\n",
      "16:\ttest: 0.8679190\tbest: 0.8679190 (16)\ttotal: 58.4s\tremaining: 13m 20s\n",
      "17:\ttest: 0.8679640\tbest: 0.8679640 (17)\ttotal: 1m 1s\tremaining: 13m 16s\n",
      "18:\ttest: 0.8679841\tbest: 0.8679841 (18)\ttotal: 1m 5s\tremaining: 13m 17s\n",
      "19:\ttest: 0.8684530\tbest: 0.8684530 (19)\ttotal: 1m 9s\tremaining: 13m 16s\n",
      "20:\ttest: 0.8692567\tbest: 0.8692567 (20)\ttotal: 1m 13s\tremaining: 13m 16s\n",
      "21:\ttest: 0.8695301\tbest: 0.8695301 (21)\ttotal: 1m 16s\tremaining: 13m 12s\n",
      "22:\ttest: 0.8701436\tbest: 0.8701436 (22)\ttotal: 1m 19s\tremaining: 13m 8s\n",
      "23:\ttest: 0.8701506\tbest: 0.8701506 (23)\ttotal: 1m 22s\tremaining: 13m 1s\n",
      "24:\ttest: 0.8701571\tbest: 0.8701571 (24)\ttotal: 1m 24s\tremaining: 12m 44s\n",
      "25:\ttest: 0.8702419\tbest: 0.8702419 (25)\ttotal: 1m 27s\tremaining: 12m 37s\n",
      "26:\ttest: 0.8702427\tbest: 0.8702427 (26)\ttotal: 1m 31s\tremaining: 12m 31s\n",
      "27:\ttest: 0.8703247\tbest: 0.8703247 (27)\ttotal: 1m 34s\tremaining: 12m 28s\n",
      "28:\ttest: 0.8705972\tbest: 0.8705972 (28)\ttotal: 1m 37s\tremaining: 12m 26s\n",
      "29:\ttest: 0.8711602\tbest: 0.8711602 (29)\ttotal: 1m 41s\tremaining: 12m 21s\n",
      "30:\ttest: 0.8714170\tbest: 0.8714170 (30)\ttotal: 1m 44s\tremaining: 12m 14s\n",
      "31:\ttest: 0.8714187\tbest: 0.8714187 (31)\ttotal: 1m 46s\tremaining: 12m 5s\n",
      "32:\ttest: 0.8714187\tbest: 0.8714187 (31)\ttotal: 1m 47s\tremaining: 11m 45s\n",
      "33:\ttest: 0.8714360\tbest: 0.8714360 (33)\ttotal: 1m 50s\tremaining: 11m 40s\n",
      "34:\ttest: 0.8714788\tbest: 0.8714788 (34)\ttotal: 1m 53s\tremaining: 11m 34s\n",
      "35:\ttest: 0.8714786\tbest: 0.8714788 (34)\ttotal: 1m 55s\tremaining: 11m 28s\n",
      "36:\ttest: 0.8714791\tbest: 0.8714791 (36)\ttotal: 1m 57s\tremaining: 11m 15s\n",
      "37:\ttest: 0.8720353\tbest: 0.8720353 (37)\ttotal: 2m\tremaining: 11m 13s\n",
      "38:\ttest: 0.8720585\tbest: 0.8720585 (38)\ttotal: 2m 3s\tremaining: 11m 9s\n",
      "39:\ttest: 0.8720586\tbest: 0.8720586 (39)\ttotal: 2m 7s\tremaining: 11m 7s\n",
      "40:\ttest: 0.8720699\tbest: 0.8720699 (40)\ttotal: 2m 9s\tremaining: 11m\n",
      "41:\ttest: 0.8720749\tbest: 0.8720749 (41)\ttotal: 2m 12s\tremaining: 10m 57s\n",
      "42:\ttest: 0.8721037\tbest: 0.8721037 (42)\ttotal: 2m 16s\tremaining: 10m 55s\n",
      "43:\ttest: 0.8728119\tbest: 0.8728119 (43)\ttotal: 2m 19s\tremaining: 10m 53s\n",
      "44:\ttest: 0.8728114\tbest: 0.8728119 (43)\ttotal: 2m 22s\tremaining: 10m 48s\n",
      "45:\ttest: 0.8730836\tbest: 0.8730836 (45)\ttotal: 2m 25s\tremaining: 10m 46s\n",
      "46:\ttest: 0.8730949\tbest: 0.8730949 (46)\ttotal: 2m 29s\tremaining: 10m 44s\n",
      "47:\ttest: 0.8734592\tbest: 0.8734592 (47)\ttotal: 2m 32s\tremaining: 10m 41s\n",
      "48:\ttest: 0.8734599\tbest: 0.8734599 (48)\ttotal: 2m 35s\tremaining: 10m 39s\n",
      "49:\ttest: 0.8734736\tbest: 0.8734736 (49)\ttotal: 2m 38s\tremaining: 10m 34s\n",
      "50:\ttest: 0.8735312\tbest: 0.8735312 (50)\ttotal: 2m 42s\tremaining: 10m 32s\n",
      "51:\ttest: 0.8735835\tbest: 0.8735835 (51)\ttotal: 2m 45s\tremaining: 10m 30s\n",
      "52:\ttest: 0.8735959\tbest: 0.8735959 (52)\ttotal: 2m 48s\tremaining: 10m 25s\n",
      "53:\ttest: 0.8736037\tbest: 0.8736037 (53)\ttotal: 2m 52s\tremaining: 10m 24s\n",
      "54:\ttest: 0.8736081\tbest: 0.8736081 (54)\ttotal: 2m 55s\tremaining: 10m 21s\n",
      "55:\ttest: 0.8736081\tbest: 0.8736081 (55)\ttotal: 2m 58s\tremaining: 10m 16s\n",
      "56:\ttest: 0.8736078\tbest: 0.8736081 (55)\ttotal: 3m\tremaining: 10m 12s\n",
      "57:\ttest: 0.8736158\tbest: 0.8736158 (57)\ttotal: 3m 3s\tremaining: 10m 7s\n",
      "58:\ttest: 0.8736175\tbest: 0.8736175 (58)\ttotal: 3m 6s\tremaining: 10m 2s\n",
      "59:\ttest: 0.8736455\tbest: 0.8736455 (59)\ttotal: 3m 9s\tremaining: 9m 59s\n",
      "60:\ttest: 0.8736475\tbest: 0.8736475 (60)\ttotal: 3m 11s\tremaining: 9m 54s\n",
      "61:\ttest: 0.8736520\tbest: 0.8736520 (61)\ttotal: 3m 14s\tremaining: 9m 50s\n",
      "62:\ttest: 0.8736555\tbest: 0.8736555 (62)\ttotal: 3m 17s\tremaining: 9m 47s\n",
      "63:\ttest: 0.8736634\tbest: 0.8736634 (63)\ttotal: 3m 21s\tremaining: 9m 44s\n",
      "64:\ttest: 0.8736595\tbest: 0.8736634 (63)\ttotal: 3m 24s\tremaining: 9m 41s\n",
      "65:\ttest: 0.8738130\tbest: 0.8738130 (65)\ttotal: 3m 27s\tremaining: 9m 39s\n",
      "66:\ttest: 0.8740220\tbest: 0.8740220 (66)\ttotal: 3m 31s\tremaining: 9m 37s\n",
      "67:\ttest: 0.8741167\tbest: 0.8741167 (67)\ttotal: 3m 35s\tremaining: 9m 35s\n",
      "68:\ttest: 0.8742766\tbest: 0.8742766 (68)\ttotal: 3m 38s\tremaining: 9m 33s\n",
      "69:\ttest: 0.8742872\tbest: 0.8742872 (69)\ttotal: 3m 41s\tremaining: 9m 29s\n",
      "70:\ttest: 0.8743375\tbest: 0.8743375 (70)\ttotal: 3m 44s\tremaining: 9m 26s\n",
      "71:\ttest: 0.8747085\tbest: 0.8747085 (71)\ttotal: 3m 47s\tremaining: 9m 21s\n",
      "72:\ttest: 0.8747231\tbest: 0.8747231 (72)\ttotal: 3m 50s\tremaining: 9m 19s\n",
      "73:\ttest: 0.8747451\tbest: 0.8747451 (73)\ttotal: 3m 54s\tremaining: 9m 16s\n",
      "74:\ttest: 0.8747443\tbest: 0.8747451 (73)\ttotal: 3m 57s\tremaining: 9m 14s\n",
      "75:\ttest: 0.8747684\tbest: 0.8747684 (75)\ttotal: 4m\tremaining: 9m 11s\n",
      "76:\ttest: 0.8751083\tbest: 0.8751083 (76)\ttotal: 4m 4s\tremaining: 9m 8s\n",
      "77:\ttest: 0.8751097\tbest: 0.8751097 (77)\ttotal: 4m 6s\tremaining: 9m 4s\n",
      "78:\ttest: 0.8751293\tbest: 0.8751293 (78)\ttotal: 4m 9s\tremaining: 9m\n",
      "79:\ttest: 0.8751277\tbest: 0.8751293 (78)\ttotal: 4m 13s\tremaining: 8m 57s\n",
      "80:\ttest: 0.8751289\tbest: 0.8751293 (78)\ttotal: 4m 16s\tremaining: 8m 54s\n",
      "81:\ttest: 0.8751989\tbest: 0.8751989 (81)\ttotal: 4m 20s\tremaining: 8m 52s\n",
      "82:\ttest: 0.8752004\tbest: 0.8752004 (82)\ttotal: 4m 23s\tremaining: 8m 49s\n",
      "83:\ttest: 0.8752091\tbest: 0.8752091 (83)\ttotal: 4m 26s\tremaining: 8m 47s\n",
      "84:\ttest: 0.8752112\tbest: 0.8752112 (84)\ttotal: 4m 29s\tremaining: 8m 43s\n",
      "85:\ttest: 0.8753188\tbest: 0.8753188 (85)\ttotal: 4m 33s\tremaining: 8m 41s\n",
      "86:\ttest: 0.8753188\tbest: 0.8753188 (85)\ttotal: 4m 35s\tremaining: 8m 36s\n",
      "87:\ttest: 0.8753188\tbest: 0.8753188 (87)\ttotal: 4m 38s\tremaining: 8m 33s\n",
      "88:\ttest: 0.8753179\tbest: 0.8753188 (87)\ttotal: 4m 42s\tremaining: 8m 30s\n",
      "89:\ttest: 0.8755191\tbest: 0.8755191 (89)\ttotal: 4m 45s\tremaining: 8m 27s\n",
      "90:\ttest: 0.8755198\tbest: 0.8755198 (90)\ttotal: 4m 49s\tremaining: 8m 25s\n",
      "91:\ttest: 0.8755231\tbest: 0.8755231 (91)\ttotal: 4m 52s\tremaining: 8m 21s\n",
      "92:\ttest: 0.8755305\tbest: 0.8755305 (92)\ttotal: 4m 55s\tremaining: 8m 18s\n",
      "93:\ttest: 0.8755210\tbest: 0.8755305 (92)\ttotal: 4m 59s\tremaining: 8m 16s\n",
      "94:\ttest: 0.8755171\tbest: 0.8755305 (92)\ttotal: 5m 1s\tremaining: 8m 12s\n",
      "95:\ttest: 0.8755195\tbest: 0.8755305 (92)\ttotal: 5m 4s\tremaining: 8m 8s\n",
      "96:\ttest: 0.8755194\tbest: 0.8755305 (92)\ttotal: 5m 7s\tremaining: 8m 5s\n",
      "97:\ttest: 0.8755271\tbest: 0.8755305 (92)\ttotal: 5m 10s\tremaining: 8m 2s\n",
      "98:\ttest: 0.8755364\tbest: 0.8755364 (98)\ttotal: 5m 14s\tremaining: 7m 59s\n",
      "99:\ttest: 0.8755395\tbest: 0.8755395 (99)\ttotal: 5m 17s\tremaining: 7m 56s\n",
      "100:\ttest: 0.8755444\tbest: 0.8755444 (100)\ttotal: 5m 20s\tremaining: 7m 52s\n",
      "101:\ttest: 0.8755442\tbest: 0.8755444 (100)\ttotal: 5m 23s\tremaining: 7m 49s\n",
      "102:\ttest: 0.8755506\tbest: 0.8755506 (102)\ttotal: 5m 27s\tremaining: 7m 47s\n",
      "103:\ttest: 0.8755496\tbest: 0.8755506 (102)\ttotal: 5m 30s\tremaining: 7m 44s\n",
      "104:\ttest: 0.8755504\tbest: 0.8755506 (102)\ttotal: 5m 34s\tremaining: 7m 41s\n",
      "105:\ttest: 0.8755529\tbest: 0.8755529 (105)\ttotal: 5m 37s\tremaining: 7m 38s\n",
      "106:\ttest: 0.8755527\tbest: 0.8755529 (105)\ttotal: 5m 39s\tremaining: 7m 34s\n",
      "107:\ttest: 0.8755689\tbest: 0.8755689 (107)\ttotal: 5m 43s\tremaining: 7m 31s\n",
      "108:\ttest: 0.8755699\tbest: 0.8755699 (108)\ttotal: 5m 46s\tremaining: 7m 28s\n",
      "109:\ttest: 0.8755851\tbest: 0.8755851 (109)\ttotal: 5m 49s\tremaining: 7m 25s\n",
      "110:\ttest: 0.8756192\tbest: 0.8756192 (110)\ttotal: 5m 53s\tremaining: 7m 23s\n",
      "111:\ttest: 0.8756209\tbest: 0.8756209 (111)\ttotal: 5m 56s\tremaining: 7m 19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112:\ttest: 0.8756832\tbest: 0.8756832 (112)\ttotal: 6m\tremaining: 7m 16s\n",
      "113:\ttest: 0.8756836\tbest: 0.8756836 (113)\ttotal: 6m 3s\tremaining: 7m 13s\n",
      "114:\ttest: 0.8762644\tbest: 0.8762644 (114)\ttotal: 6m 6s\tremaining: 7m 10s\n",
      "115:\ttest: 0.8762659\tbest: 0.8762659 (115)\ttotal: 6m 10s\tremaining: 7m 7s\n",
      "116:\ttest: 0.8762747\tbest: 0.8762747 (116)\ttotal: 6m 13s\tremaining: 7m 4s\n",
      "117:\ttest: 0.8762685\tbest: 0.8762747 (116)\ttotal: 6m 16s\tremaining: 7m 1s\n",
      "118:\ttest: 0.8762744\tbest: 0.8762747 (116)\ttotal: 6m 19s\tremaining: 6m 57s\n",
      "119:\ttest: 0.8762772\tbest: 0.8762772 (119)\ttotal: 6m 23s\tremaining: 6m 55s\n",
      "120:\ttest: 0.8765420\tbest: 0.8765420 (120)\ttotal: 6m 26s\tremaining: 6m 52s\n",
      "121:\ttest: 0.8765402\tbest: 0.8765420 (120)\ttotal: 6m 30s\tremaining: 6m 49s\n",
      "122:\ttest: 0.8765492\tbest: 0.8765492 (122)\ttotal: 6m 33s\tremaining: 6m 45s\n",
      "123:\ttest: 0.8765592\tbest: 0.8765592 (123)\ttotal: 6m 36s\tremaining: 6m 43s\n",
      "124:\ttest: 0.8765804\tbest: 0.8765804 (124)\ttotal: 6m 39s\tremaining: 6m 39s\n",
      "125:\ttest: 0.8767210\tbest: 0.8767210 (125)\ttotal: 6m 43s\tremaining: 6m 36s\n",
      "126:\ttest: 0.8767322\tbest: 0.8767322 (126)\ttotal: 6m 46s\tremaining: 6m 33s\n",
      "127:\ttest: 0.8768449\tbest: 0.8768449 (127)\ttotal: 6m 50s\tremaining: 6m 31s\n",
      "128:\ttest: 0.8770210\tbest: 0.8770210 (128)\ttotal: 6m 53s\tremaining: 6m 28s\n",
      "129:\ttest: 0.8770361\tbest: 0.8770361 (129)\ttotal: 6m 56s\tremaining: 6m 24s\n",
      "130:\ttest: 0.8770358\tbest: 0.8770361 (129)\ttotal: 6m 59s\tremaining: 6m 21s\n",
      "131:\ttest: 0.8770441\tbest: 0.8770441 (131)\ttotal: 7m 3s\tremaining: 6m 18s\n",
      "132:\ttest: 0.8770454\tbest: 0.8770454 (132)\ttotal: 7m 6s\tremaining: 6m 14s\n",
      "133:\ttest: 0.8771169\tbest: 0.8771169 (133)\ttotal: 7m 9s\tremaining: 6m 12s\n",
      "134:\ttest: 0.8771287\tbest: 0.8771287 (134)\ttotal: 7m 13s\tremaining: 6m 9s\n",
      "135:\ttest: 0.8771297\tbest: 0.8771297 (135)\ttotal: 7m 16s\tremaining: 6m 5s\n",
      "136:\ttest: 0.8771796\tbest: 0.8771796 (136)\ttotal: 7m 19s\tremaining: 6m 2s\n",
      "137:\ttest: 0.8771793\tbest: 0.8771796 (136)\ttotal: 7m 22s\tremaining: 5m 59s\n",
      "138:\ttest: 0.8771801\tbest: 0.8771801 (138)\ttotal: 7m 26s\tremaining: 5m 56s\n",
      "139:\ttest: 0.8771764\tbest: 0.8771801 (138)\ttotal: 7m 28s\tremaining: 5m 52s\n",
      "140:\ttest: 0.8771760\tbest: 0.8771801 (138)\ttotal: 7m 31s\tremaining: 5m 49s\n",
      "141:\ttest: 0.8771810\tbest: 0.8771810 (141)\ttotal: 7m 35s\tremaining: 5m 46s\n",
      "142:\ttest: 0.8771852\tbest: 0.8771852 (142)\ttotal: 7m 38s\tremaining: 5m 43s\n",
      "143:\ttest: 0.8771865\tbest: 0.8771865 (143)\ttotal: 7m 41s\tremaining: 5m 40s\n",
      "144:\ttest: 0.8771848\tbest: 0.8771865 (143)\ttotal: 7m 45s\tremaining: 5m 36s\n",
      "145:\ttest: 0.8771817\tbest: 0.8771865 (143)\ttotal: 7m 48s\tremaining: 5m 33s\n",
      "146:\ttest: 0.8774781\tbest: 0.8774781 (146)\ttotal: 7m 51s\tremaining: 5m 30s\n",
      "147:\ttest: 0.8775589\tbest: 0.8775589 (147)\ttotal: 7m 55s\tremaining: 5m 28s\n",
      "148:\ttest: 0.8775641\tbest: 0.8775641 (148)\ttotal: 7m 59s\tremaining: 5m 25s\n",
      "149:\ttest: 0.8775635\tbest: 0.8775641 (148)\ttotal: 8m 1s\tremaining: 5m 21s\n",
      "150:\ttest: 0.8776441\tbest: 0.8776441 (150)\ttotal: 8m 5s\tremaining: 5m 18s\n",
      "151:\ttest: 0.8776541\tbest: 0.8776541 (151)\ttotal: 8m 9s\tremaining: 5m 15s\n",
      "152:\ttest: 0.8776491\tbest: 0.8776541 (151)\ttotal: 8m 12s\tremaining: 5m 12s\n",
      "153:\ttest: 0.8776487\tbest: 0.8776541 (151)\ttotal: 8m 15s\tremaining: 5m 8s\n",
      "154:\ttest: 0.8776483\tbest: 0.8776541 (151)\ttotal: 8m 18s\tremaining: 5m 5s\n",
      "155:\ttest: 0.8776489\tbest: 0.8776541 (151)\ttotal: 8m 21s\tremaining: 5m 2s\n",
      "156:\ttest: 0.8776490\tbest: 0.8776541 (151)\ttotal: 8m 25s\tremaining: 4m 59s\n",
      "157:\ttest: 0.8776587\tbest: 0.8776587 (157)\ttotal: 8m 28s\tremaining: 4m 56s\n",
      "158:\ttest: 0.8780563\tbest: 0.8780563 (158)\ttotal: 8m 32s\tremaining: 4m 53s\n",
      "159:\ttest: 0.8782090\tbest: 0.8782090 (159)\ttotal: 8m 35s\tremaining: 4m 50s\n",
      "160:\ttest: 0.8782091\tbest: 0.8782091 (160)\ttotal: 8m 38s\tremaining: 4m 46s\n",
      "161:\ttest: 0.8781840\tbest: 0.8782091 (160)\ttotal: 8m 41s\tremaining: 4m 43s\n",
      "162:\ttest: 0.8781856\tbest: 0.8782091 (160)\ttotal: 8m 45s\tremaining: 4m 40s\n",
      "163:\ttest: 0.8781892\tbest: 0.8782091 (160)\ttotal: 8m 49s\tremaining: 4m 37s\n",
      "164:\ttest: 0.8781854\tbest: 0.8782091 (160)\ttotal: 8m 52s\tremaining: 4m 34s\n",
      "165:\ttest: 0.8781853\tbest: 0.8782091 (160)\ttotal: 8m 55s\tremaining: 4m 31s\n",
      "166:\ttest: 0.8781860\tbest: 0.8782091 (160)\ttotal: 8m 58s\tremaining: 4m 27s\n",
      "167:\ttest: 0.8781875\tbest: 0.8782091 (160)\ttotal: 9m 1s\tremaining: 4m 24s\n",
      "168:\ttest: 0.8781895\tbest: 0.8782091 (160)\ttotal: 9m 4s\tremaining: 4m 21s\n",
      "169:\ttest: 0.8781881\tbest: 0.8782091 (160)\ttotal: 9m 8s\tremaining: 4m 17s\n",
      "170:\ttest: 0.8781942\tbest: 0.8782091 (160)\ttotal: 9m 10s\tremaining: 4m 14s\n",
      "171:\ttest: 0.8781949\tbest: 0.8782091 (160)\ttotal: 9m 13s\tremaining: 4m 11s\n",
      "172:\ttest: 0.8781970\tbest: 0.8782091 (160)\ttotal: 9m 16s\tremaining: 4m 7s\n",
      "173:\ttest: 0.8781971\tbest: 0.8782091 (160)\ttotal: 9m 19s\tremaining: 4m 4s\n",
      "174:\ttest: 0.8781983\tbest: 0.8782091 (160)\ttotal: 9m 21s\tremaining: 4m\n",
      "175:\ttest: 0.8782024\tbest: 0.8782091 (160)\ttotal: 9m 25s\tremaining: 3m 57s\n",
      "176:\ttest: 0.8783626\tbest: 0.8783626 (176)\ttotal: 9m 28s\tremaining: 3m 54s\n",
      "177:\ttest: 0.8783697\tbest: 0.8783697 (177)\ttotal: 9m 32s\tremaining: 3m 51s\n",
      "178:\ttest: 0.8783896\tbest: 0.8783896 (178)\ttotal: 9m 35s\tremaining: 3m 48s\n",
      "179:\ttest: 0.8783846\tbest: 0.8783896 (178)\ttotal: 9m 39s\tremaining: 3m 45s\n",
      "180:\ttest: 0.8783883\tbest: 0.8783896 (178)\ttotal: 9m 42s\tremaining: 3m 41s\n",
      "181:\ttest: 0.8783894\tbest: 0.8783896 (178)\ttotal: 9m 45s\tremaining: 3m 38s\n",
      "182:\ttest: 0.8784103\tbest: 0.8784103 (182)\ttotal: 9m 48s\tremaining: 3m 35s\n",
      "183:\ttest: 0.8784103\tbest: 0.8784103 (183)\ttotal: 9m 51s\tremaining: 3m 32s\n",
      "184:\ttest: 0.8785745\tbest: 0.8785745 (184)\ttotal: 9m 55s\tremaining: 3m 29s\n",
      "185:\ttest: 0.8785732\tbest: 0.8785745 (184)\ttotal: 9m 58s\tremaining: 3m 25s\n",
      "186:\ttest: 0.8785562\tbest: 0.8785745 (184)\ttotal: 10m\tremaining: 3m 22s\n",
      "187:\ttest: 0.8785656\tbest: 0.8785745 (184)\ttotal: 10m 3s\tremaining: 3m 19s\n",
      "188:\ttest: 0.8785657\tbest: 0.8785745 (184)\ttotal: 10m 6s\tremaining: 3m 15s\n",
      "189:\ttest: 0.8785680\tbest: 0.8785745 (184)\ttotal: 10m 9s\tremaining: 3m 12s\n",
      "190:\ttest: 0.8785794\tbest: 0.8785794 (190)\ttotal: 10m 13s\tremaining: 3m 9s\n",
      "191:\ttest: 0.8786030\tbest: 0.8786030 (191)\ttotal: 10m 16s\tremaining: 3m 6s\n",
      "192:\ttest: 0.8786015\tbest: 0.8786030 (191)\ttotal: 10m 19s\tremaining: 3m 2s\n",
      "193:\ttest: 0.8785958\tbest: 0.8786030 (191)\ttotal: 10m 23s\tremaining: 2m 59s\n",
      "194:\ttest: 0.8785930\tbest: 0.8786030 (191)\ttotal: 10m 26s\tremaining: 2m 56s\n",
      "195:\ttest: 0.8785927\tbest: 0.8786030 (191)\ttotal: 10m 29s\tremaining: 2m 53s\n",
      "196:\ttest: 0.8785942\tbest: 0.8786030 (191)\ttotal: 10m 31s\tremaining: 2m 50s\n",
      "197:\ttest: 0.8785886\tbest: 0.8786030 (191)\ttotal: 10m 34s\tremaining: 2m 46s\n",
      "198:\ttest: 0.8785864\tbest: 0.8786030 (191)\ttotal: 10m 37s\tremaining: 2m 43s\n",
      "199:\ttest: 0.8785876\tbest: 0.8786030 (191)\ttotal: 10m 39s\tremaining: 2m 39s\n",
      "200:\ttest: 0.8785892\tbest: 0.8786030 (191)\ttotal: 10m 42s\tremaining: 2m 36s\n",
      "201:\ttest: 0.8785888\tbest: 0.8786030 (191)\ttotal: 10m 45s\tremaining: 2m 33s\n",
      "202:\ttest: 0.8786018\tbest: 0.8786030 (191)\ttotal: 10m 48s\tremaining: 2m 30s\n",
      "203:\ttest: 0.8787010\tbest: 0.8787010 (203)\ttotal: 10m 52s\tremaining: 2m 27s\n",
      "204:\ttest: 0.8787224\tbest: 0.8787224 (204)\ttotal: 10m 55s\tremaining: 2m 23s\n",
      "205:\ttest: 0.8787248\tbest: 0.8787248 (205)\ttotal: 10m 59s\tremaining: 2m 20s\n",
      "206:\ttest: 0.8787362\tbest: 0.8787362 (206)\ttotal: 11m 2s\tremaining: 2m 17s\n",
      "207:\ttest: 0.8787360\tbest: 0.8787362 (206)\ttotal: 11m 6s\tremaining: 2m 14s\n",
      "208:\ttest: 0.8787528\tbest: 0.8787528 (208)\ttotal: 11m 9s\tremaining: 2m 11s\n",
      "209:\ttest: 0.8787522\tbest: 0.8787528 (208)\ttotal: 11m 13s\tremaining: 2m 8s\n",
      "210:\ttest: 0.8787554\tbest: 0.8787554 (210)\ttotal: 11m 16s\tremaining: 2m 5s\n",
      "211:\ttest: 0.8787617\tbest: 0.8787617 (211)\ttotal: 11m 19s\tremaining: 2m 1s\n",
      "212:\ttest: 0.8787594\tbest: 0.8787617 (211)\ttotal: 11m 23s\tremaining: 1m 58s\n",
      "213:\ttest: 0.8787693\tbest: 0.8787693 (213)\ttotal: 11m 26s\tremaining: 1m 55s\n",
      "214:\ttest: 0.8787836\tbest: 0.8787836 (214)\ttotal: 11m 30s\tremaining: 1m 52s\n",
      "215:\ttest: 0.8787837\tbest: 0.8787837 (215)\ttotal: 11m 32s\tremaining: 1m 49s\n",
      "216:\ttest: 0.8787812\tbest: 0.8787837 (215)\ttotal: 11m 36s\tremaining: 1m 45s\n",
      "217:\ttest: 0.8787831\tbest: 0.8787837 (215)\ttotal: 11m 40s\tremaining: 1m 42s\n",
      "218:\ttest: 0.8787832\tbest: 0.8787837 (215)\ttotal: 11m 43s\tremaining: 1m 39s\n",
      "219:\ttest: 0.8787820\tbest: 0.8787837 (215)\ttotal: 11m 47s\tremaining: 1m 36s\n",
      "220:\ttest: 0.8787769\tbest: 0.8787837 (215)\ttotal: 11m 49s\tremaining: 1m 33s\n",
      "221:\ttest: 0.8787797\tbest: 0.8787837 (215)\ttotal: 11m 52s\tremaining: 1m 29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222:\ttest: 0.8787818\tbest: 0.8787837 (215)\ttotal: 11m 55s\tremaining: 1m 26s\n",
      "223:\ttest: 0.8788685\tbest: 0.8788685 (223)\ttotal: 11m 58s\tremaining: 1m 23s\n",
      "224:\ttest: 0.8788676\tbest: 0.8788685 (223)\ttotal: 12m 1s\tremaining: 1m 20s\n",
      "225:\ttest: 0.8788684\tbest: 0.8788685 (223)\ttotal: 12m 5s\tremaining: 1m 17s\n",
      "226:\ttest: 0.8788652\tbest: 0.8788685 (223)\ttotal: 12m 7s\tremaining: 1m 13s\n",
      "227:\ttest: 0.8788700\tbest: 0.8788700 (227)\ttotal: 12m 10s\tremaining: 1m 10s\n",
      "228:\ttest: 0.8789035\tbest: 0.8789035 (228)\ttotal: 12m 14s\tremaining: 1m 7s\n",
      "229:\ttest: 0.8789057\tbest: 0.8789057 (229)\ttotal: 12m 17s\tremaining: 1m 4s\n",
      "230:\ttest: 0.8792185\tbest: 0.8792185 (230)\ttotal: 12m 20s\tremaining: 1m\n",
      "231:\ttest: 0.8792228\tbest: 0.8792228 (231)\ttotal: 12m 24s\tremaining: 57.7s\n",
      "232:\ttest: 0.8792506\tbest: 0.8792506 (232)\ttotal: 12m 28s\tremaining: 54.6s\n",
      "233:\ttest: 0.8792623\tbest: 0.8792623 (233)\ttotal: 12m 31s\tremaining: 51.4s\n",
      "234:\ttest: 0.8792624\tbest: 0.8792624 (234)\ttotal: 12m 34s\tremaining: 48.1s\n",
      "235:\ttest: 0.8792666\tbest: 0.8792666 (235)\ttotal: 12m 36s\tremaining: 44.9s\n",
      "236:\ttest: 0.8792667\tbest: 0.8792667 (236)\ttotal: 12m 40s\tremaining: 41.7s\n",
      "237:\ttest: 0.8792744\tbest: 0.8792744 (237)\ttotal: 12m 43s\tremaining: 38.5s\n",
      "238:\ttest: 0.8792793\tbest: 0.8792793 (238)\ttotal: 12m 46s\tremaining: 35.3s\n",
      "239:\ttest: 0.8792825\tbest: 0.8792825 (239)\ttotal: 12m 50s\tremaining: 32.1s\n",
      "240:\ttest: 0.8792808\tbest: 0.8792825 (239)\ttotal: 12m 53s\tremaining: 28.9s\n",
      "241:\ttest: 0.8792804\tbest: 0.8792825 (239)\ttotal: 12m 56s\tremaining: 25.7s\n",
      "242:\ttest: 0.8792789\tbest: 0.8792825 (239)\ttotal: 12m 59s\tremaining: 22.5s\n",
      "243:\ttest: 0.8792801\tbest: 0.8792825 (239)\ttotal: 13m 2s\tremaining: 19.2s\n",
      "244:\ttest: 0.8793176\tbest: 0.8793176 (244)\ttotal: 13m 6s\tremaining: 16s\n",
      "245:\ttest: 0.8793198\tbest: 0.8793198 (245)\ttotal: 13m 9s\tremaining: 12.8s\n",
      "246:\ttest: 0.8793218\tbest: 0.8793218 (246)\ttotal: 13m 12s\tremaining: 9.62s\n",
      "247:\ttest: 0.8793219\tbest: 0.8793219 (247)\ttotal: 13m 15s\tremaining: 6.42s\n",
      "248:\ttest: 0.8793231\tbest: 0.8793231 (248)\ttotal: 13m 19s\tremaining: 3.21s\n",
      "249:\ttest: 0.8793229\tbest: 0.8793231 (248)\ttotal: 13m 22s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8793230568\n",
      "bestIteration = 248\n",
      "\n",
      "Shrink model to first 249 iterations.\n",
      "OOf score 0.13640318170519514\n"
     ]
    }
   ],
   "source": [
    "trn_data = Pool(val_train[features], label=val_train['target'],cat_features = cat_cols)\n",
    "\n",
    "clf = CatBoost(cat_params)\n",
    "clf.fit(trn_data,verbose_eval = True,eval_set=(trn_data))  \n",
    "predictions_cat = clf.predict(test[features],prediction_type='Probability')[:,1]\n",
    "oof_cat = clf.predict(val_train[features],prediction_type='Probability')[:,1]\n",
    "print ('OOf score', f1_score(val_train['target'], (oof_cat > 0.05).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOf score 0.1388920691516331\n"
     ]
    }
   ],
   "source": [
    "## Aveage the  two models for train\n",
    "print ('OOf score', f1_score(val_train['target'], ((0.5*oof_cat) + (0.5*oof_lgb) > 0.05).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Average two models for test\n",
    "predictions = (0.5*predictions_cat) + (0.5*predictions_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.995385\n",
       "1    0.004615\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_train['target'].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.995005\n",
       "1    0.004995\n",
       "Name: prediction, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred_prob'] = predictions\n",
    "# test['prediction'] = (test['pred_prob']>0.07).astype(int) ## Ensembling_07        LB:0.123049956178791      \n",
    "# test['prediction'] = (test['pred_prob']>0.06).astype(int) ## Ensembling_06        LB:0.12304120719675\n",
    "# test['prediction'] = (test['pred_prob']>0.05).astype(int) ## Ensembling_05        LB:\n",
    "test['prediction'] = (test['pred_prob']>0.065).astype(int) ## Ensembling_065       \n",
    "\n",
    "\n",
    "\n",
    "test['prediction'].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d9yRCR8bWXM6"
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['datetime x segment_id', 'prediction']].to_csv('Ensembling_065.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYxE7fFaW6Vr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174496, 45)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLbTuQ_x8c67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.995005\n",
       "1    0.004995\n",
       "Name: prediction, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.prediction.value_counts(True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Uber Movement Competition- Modelling - v1 (1).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "neptune": {
   "notebookId": "284bdfcb-40e5-4819-b3fd-58b709e39065"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
