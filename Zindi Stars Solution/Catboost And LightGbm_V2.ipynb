{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bqWnNjTaiB4E"
   },
   "source": [
    "# Uber Movement Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6OvbHhciB4Q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pandas_profiling as pf \n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from tqdm import tqdm\n",
    "#tqdm.pandas()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "%matplotlib inline\n",
    "# !pip install pandas_profiling\n",
    "\n",
    "import gc\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier,Pool,cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Bad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.rename(columns = {'Occurrence Local Date Time':'Datetime'})\n",
    "train=train.rename(columns = {'road_segment_id':'segment_id'})\n",
    "\n",
    "### Date conversion (make dayfirst=True)\n",
    "train['Datetime'] = pd.to_datetime(train['Datetime'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_seg = ['-34.0436786939','-33.9622761744','-33.8891283413','-34.0894652753','-33.9680008638']\n",
    "for seg in bad_seg:\n",
    "    train.loc[train['segment_id'] == seg , 'longitude']  = train.loc[train['segment_id'] == seg , 'latitude']\n",
    "    train.loc[train['segment_id'] == seg , 'latitude']  = train.loc[train['segment_id'] == seg , 'segment_id']\n",
    "    train.loc[train['segment_id'] == seg , 'segment_id']  = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Reporting Agency</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Subcause</th>\n",
       "      <th>Status</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>segment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16693</td>\n",
       "      <td>88632</td>\n",
       "      <td>2016-12-09 04:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cam</td>\n",
       "      <td>Accident</td>\n",
       "      <td>Single Vehicle</td>\n",
       "      <td>18.5642</td>\n",
       "      <td>-33.9622761744</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23455</td>\n",
       "      <td>100642</td>\n",
       "      <td>2017-05-16 07:22:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cdam</td>\n",
       "      <td>Congestion</td>\n",
       "      <td>Any</td>\n",
       "      <td>18.8397</td>\n",
       "      <td>-34.0894652753</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23747</td>\n",
       "      <td>101150</td>\n",
       "      <td>2017-05-21 08:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cam</td>\n",
       "      <td>Routine Road Maintenance</td>\n",
       "      <td>Any</td>\n",
       "      <td>18.5798</td>\n",
       "      <td>-33.9680008638</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27586</td>\n",
       "      <td>108150</td>\n",
       "      <td>2017-08-30 07:12:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cam</td>\n",
       "      <td>Congestion</td>\n",
       "      <td>Any</td>\n",
       "      <td>18.6146</td>\n",
       "      <td>-33.8891283413</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30341</td>\n",
       "      <td>112789</td>\n",
       "      <td>2017-10-21 08:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cam</td>\n",
       "      <td>Stationary Vehicle</td>\n",
       "      <td>Vehicle On Shoulder</td>\n",
       "      <td>18.7424</td>\n",
       "      <td>-34.0436786939</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EventId            Datetime Reporting Agency Cause  \\\n",
       "16693    88632 2016-12-09 04:45:00              NaN   Cam   \n",
       "23455   100642 2017-05-16 07:22:00              NaN  cdam   \n",
       "23747   101150 2017-05-21 08:30:00              NaN   cam   \n",
       "27586   108150 2017-08-30 07:12:00              NaN   cam   \n",
       "30341   112789 2017-10-21 08:03:00              NaN   cam   \n",
       "\n",
       "                       Subcause               Status longitude  \\\n",
       "16693                  Accident       Single Vehicle   18.5642   \n",
       "23455                Congestion                  Any   18.8397   \n",
       "23747  Routine Road Maintenance                  Any   18.5798   \n",
       "27586                Congestion                  Any   18.6146   \n",
       "30341        Stationary Vehicle  Vehicle On Shoulder   18.7424   \n",
       "\n",
       "             latitude segment_id  \n",
       "16693  -33.9622761744        NaN  \n",
       "23455  -34.0894652753        NaN  \n",
       "23747  -33.9680008638        NaN  \n",
       "27586  -33.8891283413        NaN  \n",
       "30341  -34.0436786939        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.segment_id.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['EventId'] == 88632, 'segment_id']   = '6OTRJQF'\n",
    "train.loc[train['EventId'] == 100642, 'segment_id']   = 'Q03FQ74'\n",
    "train.loc[train['EventId'] == 101150, 'segment_id']   = 'S2QPOTD'\n",
    "train.loc[train['EventId'] == 108150, 'segment_id']   = 'LNO3W8J'\n",
    "train.loc[train['EventId'] == 112789, 'segment_id']   = 'IUTMY1U'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Reporting Agency</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Subcause</th>\n",
       "      <th>Status</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>segment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [EventId, Datetime, Reporting Agency, Cause, Subcause, Status, longitude, latitude, segment_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.segment_id.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accident Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accident = train.segment_id.value_counts().reset_index().rename(columns = {'index':'Road_Segment',\n",
    "                                                                    'segment_id':'Accident'})\n",
    "Accident['Accident'] = Accident['Accident'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accident_Per_SegmentId.csv  seg_Length.csv            seg_pavement_v2.csv\r\n",
      "Add_feat_cause.csv          seg_Length_v2.csv         seg_roadtype.csv\r\n",
      "GeoData_001to1107.csv       SegmentId_and_suburb.csv  seg_roadtype_v2.csv\r\n",
      "GeoData_1107tolast.csv      segment_id_suburb_v2.csv  train.csv\r\n",
      "\u001b[0m\u001b[01;34mroad_segments\u001b[0m/              seg_pavement.csv          weather.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Zv2JNPLiB4m"
   },
   "outputs": [],
   "source": [
    "# test = pd.read_csv('Data/SampleSubmission.csv',error_bad_lines=False)\n",
    "# Suburb = pd.read_csv(\"Data/SegmentId_and_suburb.csv\")\n",
    "\n",
    "Suburb = pd.read_csv(\"Data/segment_id_suburb_v2.csv\")\n",
    "road_type = pd.read_csv(\"Data/seg_roadtype_v2.csv\")\n",
    "road_pavement = pd.read_csv(\"Data/seg_pavement_v2.csv\")\n",
    "road_Length = pd.read_csv(\"Data/seg_Length_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Reporting Agency</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Subcause</th>\n",
       "      <th>Status</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>segment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60558</td>\n",
       "      <td>2016-01-01 00:53:00</td>\n",
       "      <td>Cam</td>\n",
       "      <td>Stationary Vehicle</td>\n",
       "      <td>Vehicle On Shoulder</td>\n",
       "      <td>Closed</td>\n",
       "      <td>18.5408955032</td>\n",
       "      <td>-33.8883</td>\n",
       "      <td>S0B3CGQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>60559</td>\n",
       "      <td>2016-01-01 00:54:00</td>\n",
       "      <td>CAMERA</td>\n",
       "      <td>Accident</td>\n",
       "      <td>With A Fixed Object</td>\n",
       "      <td>Closed</td>\n",
       "      <td>18.9307563219</td>\n",
       "      <td>-34.1409</td>\n",
       "      <td>RYJYAPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60560</td>\n",
       "      <td>2016-01-01 02:26:00</td>\n",
       "      <td>Law Enforcement</td>\n",
       "      <td>Accident</td>\n",
       "      <td>Multi Vehicle</td>\n",
       "      <td>Closed</td>\n",
       "      <td>18.5533575029</td>\n",
       "      <td>-33.9592</td>\n",
       "      <td>U3KP57C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>60561</td>\n",
       "      <td>2016-01-01 02:56:00</td>\n",
       "      <td>CAMERA</td>\n",
       "      <td>Stationary Vehicle</td>\n",
       "      <td>Vehicle On Shoulder</td>\n",
       "      <td>Closed</td>\n",
       "      <td>18.6775561589</td>\n",
       "      <td>-33.8953</td>\n",
       "      <td>RY0TRQ8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60562</td>\n",
       "      <td>2016-01-01 03:40:00</td>\n",
       "      <td>CAMERA</td>\n",
       "      <td>Accident</td>\n",
       "      <td>Multi Vehicle</td>\n",
       "      <td>Closed</td>\n",
       "      <td>18.8371319682</td>\n",
       "      <td>-34.0871</td>\n",
       "      <td>8LOVJZ3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventId            Datetime Reporting Agency               Cause  \\\n",
       "0    60558 2016-01-01 00:53:00              Cam  Stationary Vehicle   \n",
       "1    60559 2016-01-01 00:54:00           CAMERA            Accident   \n",
       "2    60560 2016-01-01 02:26:00  Law Enforcement            Accident   \n",
       "3    60561 2016-01-01 02:56:00           CAMERA  Stationary Vehicle   \n",
       "4    60562 2016-01-01 03:40:00           CAMERA            Accident   \n",
       "\n",
       "              Subcause  Status      longitude latitude segment_id  \n",
       "0  Vehicle On Shoulder  Closed  18.5408955032 -33.8883    S0B3CGQ  \n",
       "1  With A Fixed Object  Closed  18.9307563219 -34.1409    RYJYAPI  \n",
       "2        Multi Vehicle  Closed  18.5533575029 -33.9592    U3KP57C  \n",
       "3  Vehicle On Shoulder  Closed  18.6775561589 -33.8953    RY0TRQ8  \n",
       "4        Multi Vehicle  Closed  18.8371319682 -34.0871    8LOVJZ3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pd.read_csv('Data/weather.csv', sep=\";\", skiprows=6, usecols=range(14),\n",
    "               parse_dates=['Local time in Cape Town (airport)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local time in Cape Town (airport)</th>\n",
       "      <th>T</th>\n",
       "      <th>P0</th>\n",
       "      <th>P</th>\n",
       "      <th>U</th>\n",
       "      <th>DD</th>\n",
       "      <th>Ff</th>\n",
       "      <th>ff10</th>\n",
       "      <th>WW</th>\n",
       "      <th>W'W'</th>\n",
       "      <th>c</th>\n",
       "      <th>VV</th>\n",
       "      <th>Td</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-04 23:00:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>765.8</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Wind blowing from the south-southeast</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scattered clouds (40-50%) 720 m, broken clouds...</td>\n",
       "      <td>10.0 and more</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-04 22:00:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>761.2</td>\n",
       "      <td>765.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Wind blowing from the south-southeast</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scattered clouds (40-50%) 570 m, broken clouds...</td>\n",
       "      <td>10.0 and more</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-04 21:59:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>761.2</td>\n",
       "      <td>765.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Wind blowing from the south-southeast</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scattered clouds (40-50%) 570 m, broken clouds...</td>\n",
       "      <td>10.0 and more</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-04 21:01:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>761.2</td>\n",
       "      <td>765.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Wind blowing from the south-southeast</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scattered clouds (40-50%) 150 m, broken clouds...</td>\n",
       "      <td>10.0 and more</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-04 21:00:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>761.2</td>\n",
       "      <td>765.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Wind blowing from the south-southeast</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scattered clouds (40-50%) 150 m, broken clouds...</td>\n",
       "      <td>10.0 and more</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Local time in Cape Town (airport)     T     P0      P     U  \\\n",
       "0               2019-04-04 23:00:00  15.0  762.0  765.8  77.0   \n",
       "1               2019-04-04 22:00:00  16.0  761.2  765.0  77.0   \n",
       "2               2019-04-04 21:59:00  16.0  761.2  765.0  77.0   \n",
       "3               2019-04-04 21:01:00  15.0  761.2  765.0  94.0   \n",
       "4               2019-04-04 21:00:00  15.0  761.2  765.0  94.0   \n",
       "\n",
       "                                      DD   Ff  ff10   WW W'W'  \\\n",
       "0  Wind blowing from the south-southeast  6.0   NaN  NaN  NaN   \n",
       "1  Wind blowing from the south-southeast  6.0   NaN  NaN  NaN   \n",
       "2  Wind blowing from the south-southeast  6.0   NaN  NaN  NaN   \n",
       "3  Wind blowing from the south-southeast  6.0   NaN  NaN  NaN   \n",
       "4  Wind blowing from the south-southeast  6.0   NaN  NaN  NaN   \n",
       "\n",
       "                                                   c             VV    Td  \\\n",
       "0  Scattered clouds (40-50%) 720 m, broken clouds...  10.0 and more  11.0   \n",
       "1  Scattered clouds (40-50%) 570 m, broken clouds...  10.0 and more  12.0   \n",
       "2  Scattered clouds (40-50%) 570 m, broken clouds...  10.0 and more  12.0   \n",
       "3  Scattered clouds (40-50%) 150 m, broken clouds...  10.0 and more  14.0   \n",
       "4  Scattered clouds (40-50%) 150 m, broken clouds...  10.0 and more  14.0   \n",
       "\n",
       "   Unnamed: 13  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w['dt'] = w['Local time in Cape Town (airport)'].dt.round('H')\n",
    "w['dt_2'] = w['Local time in Cape Town (airport)'].dt.floor('H')\n",
    "\n",
    "w_cols = ['dt','dt_2', 'T', 'P0', 'P', 'U', 'Ff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMjZM8t1iB6S"
   },
   "source": [
    "### Get Extra Feature from Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "OoFBUkuniB6d",
    "outputId": "029e3d48-5618-4693-e4fa-aa29f6dca094",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Count of occurance of incident\n",
    "Seg_Group = train.groupby(['segment_id','Datetime']).size().reset_index(name='Counts')\n",
    "\n",
    "### Mapping the Segment_id - from text to number\n",
    "LE = LabelEncoder()\n",
    "Seg_Group['segmentid_num'] = LE.fit_transform(Seg_Group['segment_id'])\n",
    "\n",
    "# Make all 3 digits of segments\n",
    "Seg_Group['segmentid_num3'] = [str(x).zfill(3) for x in Seg_Group['segmentid_num']]\n",
    "\n",
    "# Add 'seg_' to 3digit segment_id\n",
    "Seg_Group['segment_idx'] = 'seg_'+Seg_Group.segmentid_num3.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "ThkbD05QiB7O",
    "outputId": "c65c690f-20a0-443b-ad32-6f24d67232e1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Counts</th>\n",
       "      <th>segmentid_num</th>\n",
       "      <th>segmentid_num3</th>\n",
       "      <th>segment_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>03RHJ3G</td>\n",
       "      <td>2016-01-01 09:02:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>seg_000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>03RHJ3G</td>\n",
       "      <td>2016-01-04 09:46:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>seg_000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>03RHJ3G</td>\n",
       "      <td>2016-01-04 13:29:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>seg_000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>03RHJ3G</td>\n",
       "      <td>2016-01-05 14:41:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>seg_000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>03RHJ3G</td>\n",
       "      <td>2016-01-05 16:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>seg_000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  segment_id            Datetime  Counts  segmentid_num segmentid_num3  \\\n",
       "0    03RHJ3G 2016-01-01 09:02:00       1              0            000   \n",
       "1    03RHJ3G 2016-01-04 09:46:00       1              0            000   \n",
       "2    03RHJ3G 2016-01-04 13:29:00       1              0            000   \n",
       "3    03RHJ3G 2016-01-05 14:41:00       1              0            000   \n",
       "4    03RHJ3G 2016-01-05 16:10:00       1              0            000   \n",
       "\n",
       "  segment_idx  \n",
       "0     seg_000  \n",
       "1     seg_000  \n",
       "2     seg_000  \n",
       "3     seg_000  \n",
       "4     seg_000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Seg_Group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oij26HaJiB75"
   },
   "source": [
    "### Extract unique Segment Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IynYqQaGiB8D",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "## Drop duplicate segment_id\n",
    "SegIdQ = Seg_Group[['segment_id','segment_idx','segmentid_num']].drop_duplicates()\n",
    "# segment_id_1\n",
    "SegIdQx = SegIdQ['segment_id'].unique()\n",
    "# segmen_id_2\n",
    "SegIdQx2 = SegIdQ['segment_idx'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add centre of Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.longitude = train.longitude.astype(float)\n",
    "train.latitude = train.latitude.astype(float)\n",
    "\n",
    "## Get centre location of the segment\n",
    "location =  train.groupby('segment_id').median()[['longitude', 'latitude']]\n",
    "SegIdQ = SegIdQ.merge(location, left_on=['segment_id'], how=\"left\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>segment_idx</th>\n",
       "      <th>segmentid_num</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>03RHJ3G</td>\n",
       "      <td>seg_000</td>\n",
       "      <td>0</td>\n",
       "      <td>18.459897</td>\n",
       "      <td>-33.943257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582</td>\n",
       "      <td>044ZYVD</td>\n",
       "      <td>seg_001</td>\n",
       "      <td>1</td>\n",
       "      <td>18.554505</td>\n",
       "      <td>-33.890213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613</td>\n",
       "      <td>086LLYS</td>\n",
       "      <td>seg_002</td>\n",
       "      <td>2</td>\n",
       "      <td>18.432873</td>\n",
       "      <td>-33.918816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>637</td>\n",
       "      <td>0B0QOEN</td>\n",
       "      <td>seg_003</td>\n",
       "      <td>3</td>\n",
       "      <td>18.477737</td>\n",
       "      <td>-33.917932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0F3OY57</td>\n",
       "      <td>seg_004</td>\n",
       "      <td>4</td>\n",
       "      <td>18.773261</td>\n",
       "      <td>-34.057950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    segment_id segment_idx  segmentid_num  longitude   latitude\n",
       "0      03RHJ3G     seg_000              0  18.459897 -33.943257\n",
       "582    044ZYVD     seg_001              1  18.554505 -33.890213\n",
       "613    086LLYS     seg_002              2  18.432873 -33.918816\n",
       "637    0B0QOEN     seg_003              3  18.477737 -33.917932\n",
       "790    0F3OY57     seg_004              4  18.773261 -34.057950"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SegIdQ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add other segment related feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add centre Accident_count to data_set\n",
    "SegIdQ = pd.merge(SegIdQ, Accident[['Road_Segment','Accident']], left_on='segment_id', right_on='Road_Segment', how='left') # Segment locations\n",
    "SegIdQ = pd.merge(SegIdQ, Suburb[['segment_id','suburb']], left_on='segment_id', right_on='segment_id', how='left') # Segment locations\n",
    "# SegIdQ = pd.merge(SegIdQ, Cause, left_on='segment_id', right_on='Road_Segment', how='left') # Segment locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add centre Other  to data_set\n",
    "SegIdQ = pd.merge(SegIdQ, road_Length, left_on='segment_id', right_on='segment_id', how='left') # Segment locations\n",
    "SegIdQ = pd.merge(SegIdQ, road_type, left_on='segment_id', right_on='segment_id', how='left') # Segment locations\n",
    "SegIdQ = pd.merge(SegIdQ, road_pavement, left_on='segment_id', right_on='segment_id', how='left') # Segment locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7erKy03niB8K"
   },
   "source": [
    "### Merging Train Dataset with Segment Features from NoteBook(`Geo-Spatial Features Extraction_v3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "-qZWFboMiB8N",
    "outputId": "24cddb12-806e-4c2d-db0b-052ca8533fa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train # B4 merging 53845\n",
      "Train # After merging 53845\n"
     ]
    }
   ],
   "source": [
    "trainX = pd.merge(train, SegIdQ, on=['segment_id'], how=\"left\")\n",
    "print('Train # B4 merging',len(train))\n",
    "print('Train # After merging',len(trainX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dI08znjyiB8V"
   },
   "outputs": [],
   "source": [
    "# del SegIdQ\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX.to_csv('train_transformed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdOe5-sXiB8n"
   },
   "source": [
    "### CreateTrain Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get day not in Train day and save as missing_days\n",
    "Main_day = pd.date_range('2016-01-01','2018-12-31',\n",
    "                           freq=\"1D\")\n",
    "Main_day = pd.DataFrame({'datetime':Main_day.date})\n",
    "\n",
    "train_days = trainX['Datetime'].dt.date.drop_duplicates()\n",
    "missing_days = Main_day[~Main_day['datetime'].isin(train_days)]\n",
    "\n",
    "del train_days, Main_day\n",
    "missing_days['datetime'] = pd.to_datetime(missing_days.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "iYiyXox5iB8p",
    "outputId": "824afd44-8577-4815-bdfe-9ab3260c34d6"
   },
   "outputs": [],
   "source": [
    "Data1Hour = pd.date_range('2016-01-01',\n",
    "                          '2018-12-31 23:00:00',\n",
    "                           freq=\"1h\")\n",
    "Data1Hour = pd.DataFrame({'datetime':Data1Hour})\n",
    "###Remove missing date from date range\n",
    "Data1Hour = Data1Hour[~Data1Hour['datetime'].dt.date.isin(missing_days['datetime'].dt.date)]\n",
    "\n",
    "# Generate Target\n",
    "for SegId in SegIdQx2:\n",
    "    Data1Hour[str(SegId)] = 0\n",
    "    events = trainX.loc[trainX['segment_idx'] == SegId]\n",
    "    dts = events['Datetime'].dt.floor('H')\n",
    "    dates = dts.astype(str).unique()\n",
    "    Data1Hour.loc[Data1Hour['datetime'].isin(dates), SegId] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24672, 545)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1Hour.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "UOHIPI-JiB9H",
    "outputId": "6786e5c9-d56c-49c2-ee69-8a60092e4c70"
   },
   "outputs": [],
   "source": [
    "test1Hour = pd.date_range('2019-01-01 01:00:00',\n",
    "                          '2019-03-31 23:00:00' ,\n",
    "                           freq=\"1h\")\n",
    "\n",
    "test1Hour = pd.DataFrame({'datetime':test1Hour})\n",
    "\n",
    "# Generate Target\n",
    "for SegId in SegIdQx2:\n",
    "    test1Hour[str(SegId)] = np.NAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1Hour.set_index('datetime', inplace=True)\n",
    "Data1Hour.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert seg to Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1Hour = Data1Hour.reset_index()\n",
    "test1Hour = test1Hour.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1Hour = pd.melt(Data1Hour, id_vars=['datetime'])\n",
    "Data1Hour.rename(columns={'variable': 'seg', 'value': 'target'}, inplace=True)\n",
    "Data1Hour['seg'] = Data1Hour.seg.map(lambda x: int(x[4:]))\n",
    "Data1Hour.set_index('datetime', inplace=True)\n",
    "# Data1Hour.sort_values('datetime', inplace=True)\n",
    "Data1Hour = Data1Hour.sort_values('datetime')\n",
    "\n",
    "\n",
    "\n",
    "test1Hour = pd.melt(test1Hour, id_vars=['datetime'])\n",
    "test1Hour.rename(columns={'variable': 'seg', 'value': 'target'}, inplace=True)\n",
    "test1Hour['seg'] = test1Hour.seg.map(lambda x: int(x[4:]))\n",
    "test1Hour.set_index('datetime', inplace=True)\n",
    "\n",
    "test1Hour = test1Hour.sort_values('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            seg  target\n",
       "datetime               \n",
       "2016-01-01    0       0\n",
       "2016-01-01  170       0\n",
       "2016-01-01  171       0\n",
       "2016-01-01  172       0\n",
       "2016-01-01  173       0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1Hour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDHXa28iiB-n",
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "### Timebased FeatEngineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qJovrKQiB_K"
   },
   "outputs": [],
   "source": [
    "attr = [\"Hour\",\"Year\", 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear','quarter',\"weekday_name\",\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "\n",
    "for n in attr: \n",
    "    Data1Hour[n] = getattr(Data1Hour.index, n.lower())\n",
    "    test1Hour[n] = getattr(test1Hour.index, n.lower())\n",
    "\n",
    "# Data1Hour['Elapsed'] = Data1Hour.index.astype(np.int64) // 10 ** 9\n",
    "# test1Hour['Elapsed'] = test1Hour.index.astype(np.int64) // 10 ** 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hso32GVKiB_Q"
   },
   "outputs": [],
   "source": [
    "## WeekEnd\n",
    "Data1Hour['IsWeekend'] = np.where(Data1Hour['Dayofweek'] < 5,0,1)\n",
    "test1Hour['IsWeekend'] = np.where(test1Hour['Dayofweek'] < 5,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yPust2YgiB_n"
   },
   "outputs": [],
   "source": [
    "# Holiday \n",
    "from pandas.tseries.holiday import *\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "\n",
    "class SouthAfricaHoliday(AbstractHolidayCalendar):\n",
    "   rules = [\n",
    "     Holiday('New Year', month=1, day=1, observance=sunday_to_monday),\n",
    "     Holiday('Human Rights Day', month=3, day=21, observance=sunday_to_monday),\n",
    "     Holiday('Good Friday', month=1, day=1, offset=[Easter(), Day(-2)]),\n",
    "     Holiday('Easter Monday', month=1, day=1, offset=[Easter(), Day(1)]),\n",
    "     Holiday('Freedom Day', month=4, day=27, observance=sunday_to_monday),\n",
    "     Holiday('Workers Day', month=5, day=1,observance=sunday_to_monday),\n",
    "     Holiday('Youth Day', month=6, day=16, observance=sunday_to_monday),\n",
    "     Holiday('Womens Day', month=8, day=9, observance=sunday_to_monday),\n",
    "     Holiday('Heritage Day', month=9, day=24, observance=sunday_to_monday),\n",
    "     Holiday('Day of Reconcilation', month=12, day=16, observance=sunday_to_monday),\n",
    "     Holiday('Goodwill Day', month=12, day=26, observance=sunday_to_monday),\n",
    "     Holiday('Christmas', month=12, day=25)\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eCtAdcPkiB_5",
    "outputId": "fd680563-c6ba-4953-b60c-76b5263bf0d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2016-01-01 00:00:00'), Timestamp('2019-03-31 23:00:00'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1Hour.index.min(), test1Hour.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aC_xqwLuiCAD"
   },
   "outputs": [],
   "source": [
    "hol= SouthAfricaHoliday()\n",
    "myholidays =hol.holidays(start=Data1Hour.index.min(), end =test1Hour.index.max())\n",
    "hol_day = pd.Series(myholidays)\n",
    "\n",
    "### election\n",
    "election_day = \"2019-08-03\"\n",
    "hol_day = hol_day.append(pd.to_datetime(pd.Series([election_day])),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJmoE-RBiCAX"
   },
   "outputs": [],
   "source": [
    "## Create instance of holiday in a new column\n",
    "Data1Hour['IsHoliday'] = np.where((pd.to_datetime(Data1Hour.index.date)).isin(hol_day) ,1,0)\n",
    "test1Hour['IsHoliday'] = np.where((pd.to_datetime(test1Hour.index.date)).isin(hol_day) ,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_8CGfnkiCAg"
   },
   "outputs": [],
   "source": [
    "# pay_day \n",
    "\n",
    "Data1Hour['PayDay'] = np.where((Data1Hour['Day'] < 25) ,0,1)\n",
    "Data1Hour['PayDay_Teachers'] = np.where(Data1Hour['Day'] < 22,0,1)\n",
    "\n",
    "\n",
    "test1Hour['PayDay'] = np.where((test1Hour['Day'] < 25) ,0,1)\n",
    "test1Hour['PayDay_Teachers'] = np.where(test1Hour['Day'] < 22,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1Hour['min'] = Data1Hour.index.hour*60+Data1Hour.index.minute\n",
    "test1Hour['min'] = test1Hour.index.hour*60+test1Hour.index.minute\n",
    "\n",
    "Data1Hour['Hour_sin'] = np.sin(2 * np.pi * Data1Hour['Hour']/23.0)\n",
    "Data1Hour['Hour_cos'] = np.cos(2 * np.pi * Data1Hour['Hour']/23.0)\n",
    "\n",
    "test1Hour['Hour_sin'] = np.sin(2 * np.pi * test1Hour['Hour']/23.0)\n",
    "test1Hour['Hour_cos'] = np.cos(2 * np.pi * test1Hour['Hour']/23.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seg', 'target', 'Hour', 'Year', 'Month', 'Week', 'Day', 'Dayofweek',\n",
       "       'Dayofyear', 'quarter', 'weekday_name', 'Is_month_end',\n",
       "       'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end',\n",
       "       'Is_year_start', 'IsWeekend', 'IsHoliday', 'PayDay', 'PayDay_Teachers',\n",
       "       'min', 'Hour_sin', 'Hour_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1Hour.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13421568, 24)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1Hour.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.99617\n",
       "1    0.00383\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1Hour.target.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WF7eb72iCDd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bt1EEPc5VXQ4"
   },
   "outputs": [],
   "source": [
    "## Memory reduce Function\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKJmxyLVWLaI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2062.37 MB\n",
      "Memory usage after optimization is: 603.19 MB\n",
      "Decreased by 70.8%\n",
      "Memory usage of dataframe is 216.97 MB\n",
      "Memory usage after optimization is: 96.00 MB\n",
      "Decreased by 55.8%\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(Data1Hour)\n",
    "test = reduce_mem_usage(test1Hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyMemTfUiCD-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.99617\n",
       "1    0.00383\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values('datetime')\n",
    "test = test.sort_values('datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge New features to Train and Test DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seg', 'target', 'Hour', 'Year', 'Month', 'Week', 'Day', 'Dayofweek',\n",
       "       'Dayofyear', 'quarter', 'weekday_name', 'Is_month_end',\n",
       "       'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end',\n",
       "       'Is_year_start', 'IsWeekend', 'IsHoliday', 'PayDay', 'PayDay_Teachers',\n",
       "       'min', 'Hour_sin', 'Hour_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['datetime'] = test.index\n",
    "train['datetime'] = train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge Weather\n",
    "w = w[w_cols].drop_duplicates(['dt_2'])\n",
    "train = pd.merge(train, w[w_cols], left_index=True, right_on='dt_2', how='left') # Weather\n",
    "test = pd.merge(test, w[w_cols], left_index=True, right_on='dt_2', how='left') # Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge Other New feature Stored in SegIdQ\n",
    "train = pd.merge(train, SegIdQ, left_on=['seg'], right_on=['segmentid_num'], how=\"left\")\n",
    "test = pd.merge(test, SegIdQ, left_on=['seg'], right_on=['segmentid_num'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.set_index('datetime', inplace=True)\n",
    "train.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['datetime x segment_id'] = test.index.astype('str') + ' x ' + test['segment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13421568, 42), (1174496, 43))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seg', 'target', 'Hour', 'Year', 'Month', 'Week', 'Day', 'Dayofweek',\n",
       "       'Dayofyear', 'quarter', 'weekday_name', 'Is_month_end',\n",
       "       'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end',\n",
       "       'Is_year_start', 'IsWeekend', 'IsHoliday', 'PayDay', 'PayDay_Teachers',\n",
       "       'min', 'Hour_sin', 'Hour_cos', 'dt', 'dt_2', 'T', 'P0', 'P', 'U', 'Ff',\n",
       "       'segment_id', 'segment_idx', 'segmentid_num', 'longitude', 'latitude',\n",
       "       'Road_Segment', 'Accident', 'suburb', 'length_1', 'roadno', 'surftype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Columns to be deleted\n",
    "del_col = [\n",
    "       'Day', \n",
    "#          'Dayofweek', 'Hour', \n",
    "#          'Hour_cos', 'Hour_sin',\n",
    "#        'IsHoliday', 'IsWeekend', \n",
    "       'Is_month_end', 'Is_month_start',\n",
    "       'Is_quarter_end', 'Is_quarter_start', \n",
    "       'Is_year_end', 'Is_year_start',\n",
    "       'PayDay', \n",
    "       'PayDay_Teachers', \n",
    "       'Week', \n",
    "        'min',\n",
    "       'quarter', \n",
    "#        'seg',\n",
    "    'dt',\n",
    "     'dt_2',\n",
    "     'T',\n",
    "     'P0',\n",
    "     'P',\n",
    "     'U',\n",
    "     'Ff',\n",
    "#     'RoadNo',\n",
    "#     'SURFTYPE'\n",
    "      'Cause', 'Freq', 'CatNo_cause',\n",
    "#     'longitude', 'latitude',\n",
    "#     'Accident', 'suburb',\n",
    "      'weekday_name','Dayofyear',\n",
    "      'Road_Segment_x','segment_id','Road_Segment_y','Month', 'segmentid_num','segment_idx',       \n",
    "      'target','Year','SegmentId','SegmentId_x','SegmentId_y','Road_Segment'\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seg', 'target', 'Hour', 'Year', 'Month', 'Week', 'Day', 'Dayofweek',\n",
       "       'Dayofyear', 'quarter', 'weekday_name', 'Is_month_end',\n",
       "       'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end',\n",
       "       'Is_year_start', 'IsWeekend', 'IsHoliday', 'PayDay', 'PayDay_Teachers',\n",
       "       'min', 'Hour_sin', 'Hour_cos', 'dt', 'dt_2', 'T', 'P0', 'P', 'U', 'Ff',\n",
       "       'segment_id', 'segment_idx', 'segmentid_num', 'longitude', 'latitude',\n",
       "       'Road_Segment', 'Accident', 'suburb', 'length_1', 'roadno', 'surftype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify Cat col And Encode Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Hour','Dayofweek','seg','suburb','roadno','surftype']\n",
    "LE = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    train[col] = train[col].replace({np.nan:'NaN'})\n",
    "    train[col] = LE.fit_transform(train[col])\n",
    "    \n",
    "    test[col] = test[col].replace({np.nan:'NaN'})\n",
    "    test[col] =  LE.transform(test[col])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify TrainSet\n",
    "Train with only 2018 because it is the most recent  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4752384, 42), (1201152, 42))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start      = '2018-01-01'\n",
    "split_date = '2018-10-01'\n",
    "\n",
    "\n",
    "val_train = train[(train.index >= start) & (train.index <='2018-12-31 23:00:00')]\n",
    "val_test = train[train.index >= split_date]\n",
    "\n",
    "val_train.shape, val_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove August because it contains very few number of records\n",
    "val_train = val_train[~((val_train.index >= '2018-08-01') & (val_train.index <'2018-09-01'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_train Target value count \n",
      " 0    0.995385\n",
      "1    0.004615\n",
      "Name: target, dtype: float64\n",
      "Val_test Target value count \n",
      " 0    0.993427\n",
      "1    0.006573\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print ('Val_train Target value count \\n', val_train['target'].value_counts(True))\n",
    "print ('Val_test Target value count \\n', val_test['target'].value_counts(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seg',\n",
       " 'Hour',\n",
       " 'Dayofweek',\n",
       " 'IsWeekend',\n",
       " 'IsHoliday',\n",
       " 'Hour_sin',\n",
       " 'Hour_cos',\n",
       " 'longitude',\n",
       " 'latitude',\n",
       " 'Accident',\n",
       " 'suburb',\n",
       " 'length_1',\n",
       " 'roadno',\n",
       " 'surftype']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [x for x in train.columns if x not in del_col]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 373.16 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 120.24 MB\n",
      "Decreased by 67.8%\n",
      "Memory usage of dataframe is 103.10 MB\n",
      "Memory usage after optimization is: 33.22 MB\n",
      "Decreased by 67.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "## Reduce training Features\n",
    "val_train[features] = reduce_mem_usage(val_train[features] )\n",
    "val_test[features] = reduce_mem_usage(val_test[features] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lgb Parametres\n",
    "\n",
    "lgb_params = {\n",
    "          \"booster\": \"gbtree\",\n",
    "          \"eta\": 0.05,\n",
    "         'num_iterations': 190,\n",
    "         'verbosity': 50,\n",
    "         'silent': 1,\n",
    "         'eval_metric': 'binary_logloss',\n",
    "         'seed': 2020,\n",
    "         'metric': 'binary_logloss',\n",
    "         \"max_depth\": 15,\n",
    "          'is_unbalance': True,\n",
    "          \"subsample\": 0.8,\n",
    "          \"colsample_bytree\": 0.8,\n",
    "          \"alpha\": 0.4\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "## Cat_boost Parametres\n",
    "cat_params= {\n",
    "            'num_boost_round': 250,\n",
    "            'use_best_model':True,\n",
    "            'depth': 8,\n",
    "            'random_state': 2020,\n",
    "            'eval_metric': 'AUC', \n",
    "            'loss_function': 'Logloss',\n",
    "            'verbose': True\n",
    "}\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/zindistars2/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOf score 0.13497939684468013\n"
     ]
    }
   ],
   "source": [
    "trn_data = lgb.Dataset(val_train[features], label=val_train['target'])\n",
    "clf = lgb.train(lgb_params, trn_data, 190)\n",
    "\n",
    "predictions_lgb = clf.predict(test[features])\n",
    "oof_lgb = clf.predict(val_train[features])\n",
    "print ('OOf score', f1_score(val_train['target'], (oof_lgb > 0.05).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0.13560956148808137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier,Pool,cv,CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.458621\n",
      "0:\ttest: 0.7869819\tbest: 0.7869819 (0)\ttotal: 4.06s\tremaining: 16m 51s\n",
      "1:\ttest: 0.8344682\tbest: 0.8344682 (1)\ttotal: 10.3s\tremaining: 21m 17s\n",
      "2:\ttest: 0.8383004\tbest: 0.8383004 (2)\ttotal: 16.5s\tremaining: 22m 42s\n",
      "3:\ttest: 0.8454366\tbest: 0.8454366 (3)\ttotal: 20.3s\tremaining: 20m 49s\n",
      "4:\ttest: 0.8493965\tbest: 0.8493965 (4)\ttotal: 23.7s\tremaining: 19m 18s\n",
      "5:\ttest: 0.8571752\tbest: 0.8571752 (5)\ttotal: 26.9s\tremaining: 18m 13s\n",
      "6:\ttest: 0.8582134\tbest: 0.8582134 (6)\ttotal: 30.4s\tremaining: 17m 33s\n",
      "7:\ttest: 0.8591718\tbest: 0.8591718 (7)\ttotal: 33.7s\tremaining: 16m 59s\n",
      "8:\ttest: 0.8606640\tbest: 0.8606640 (8)\ttotal: 37s\tremaining: 16m 30s\n",
      "9:\ttest: 0.8633771\tbest: 0.8633771 (9)\ttotal: 40.1s\tremaining: 16m 3s\n",
      "10:\ttest: 0.8654979\tbest: 0.8654979 (10)\ttotal: 43.7s\tremaining: 15m 49s\n",
      "11:\ttest: 0.8657193\tbest: 0.8657193 (11)\ttotal: 47.1s\tremaining: 15m 34s\n",
      "12:\ttest: 0.8670872\tbest: 0.8670872 (12)\ttotal: 50.3s\tremaining: 15m 17s\n",
      "13:\ttest: 0.8671776\tbest: 0.8671776 (13)\ttotal: 53.9s\tremaining: 15m 8s\n",
      "14:\ttest: 0.8678358\tbest: 0.8678358 (14)\ttotal: 57.1s\tremaining: 14m 53s\n",
      "15:\ttest: 0.8680278\tbest: 0.8680278 (15)\ttotal: 1m\tremaining: 14m 42s\n",
      "16:\ttest: 0.8685235\tbest: 0.8685235 (16)\ttotal: 1m 3s\tremaining: 14m 36s\n",
      "17:\ttest: 0.8686989\tbest: 0.8686989 (17)\ttotal: 1m 7s\tremaining: 14m 33s\n",
      "18:\ttest: 0.8688221\tbest: 0.8688221 (18)\ttotal: 1m 11s\tremaining: 14m 31s\n",
      "19:\ttest: 0.8694378\tbest: 0.8694378 (19)\ttotal: 1m 15s\tremaining: 14m 23s\n",
      "20:\ttest: 0.8698028\tbest: 0.8698028 (20)\ttotal: 1m 18s\tremaining: 14m 15s\n",
      "21:\ttest: 0.8701163\tbest: 0.8701163 (21)\ttotal: 1m 20s\tremaining: 13m 57s\n",
      "22:\ttest: 0.8701231\tbest: 0.8701231 (22)\ttotal: 1m 23s\tremaining: 13m 47s\n",
      "23:\ttest: 0.8709212\tbest: 0.8709212 (23)\ttotal: 1m 27s\tremaining: 13m 44s\n",
      "24:\ttest: 0.8709391\tbest: 0.8709391 (24)\ttotal: 1m 29s\tremaining: 13m 29s\n",
      "25:\ttest: 0.8709391\tbest: 0.8709391 (24)\ttotal: 1m 32s\tremaining: 13m 14s\n",
      "26:\ttest: 0.8709391\tbest: 0.8709391 (24)\ttotal: 1m 34s\tremaining: 13m 1s\n",
      "27:\ttest: 0.8709436\tbest: 0.8709436 (27)\ttotal: 1m 36s\tremaining: 12m 45s\n",
      "28:\ttest: 0.8709738\tbest: 0.8709738 (28)\ttotal: 1m 39s\tremaining: 12m 37s\n",
      "29:\ttest: 0.8709733\tbest: 0.8709738 (28)\ttotal: 1m 42s\tremaining: 12m 28s\n",
      "30:\ttest: 0.8709770\tbest: 0.8709770 (30)\ttotal: 1m 43s\tremaining: 12m 9s\n",
      "31:\ttest: 0.8711051\tbest: 0.8711051 (31)\ttotal: 1m 45s\tremaining: 12m\n",
      "32:\ttest: 0.8711185\tbest: 0.8711185 (32)\ttotal: 1m 48s\tremaining: 11m 53s\n",
      "33:\ttest: 0.8711543\tbest: 0.8711543 (33)\ttotal: 1m 51s\tremaining: 11m 50s\n",
      "34:\ttest: 0.8711664\tbest: 0.8711664 (34)\ttotal: 1m 55s\tremaining: 11m 49s\n",
      "35:\ttest: 0.8717519\tbest: 0.8717519 (35)\ttotal: 1m 58s\tremaining: 11m 45s\n",
      "36:\ttest: 0.8717717\tbest: 0.8717717 (36)\ttotal: 2m 2s\tremaining: 11m 44s\n",
      "37:\ttest: 0.8718048\tbest: 0.8718048 (37)\ttotal: 2m 5s\tremaining: 11m 39s\n",
      "38:\ttest: 0.8718130\tbest: 0.8718130 (38)\ttotal: 2m 8s\tremaining: 11m 33s\n",
      "39:\ttest: 0.8722185\tbest: 0.8722185 (39)\ttotal: 2m 11s\tremaining: 11m 30s\n",
      "40:\ttest: 0.8724565\tbest: 0.8724565 (40)\ttotal: 2m 14s\tremaining: 11m 25s\n",
      "41:\ttest: 0.8725336\tbest: 0.8725336 (41)\ttotal: 2m 17s\tremaining: 11m 21s\n",
      "42:\ttest: 0.8725476\tbest: 0.8725476 (42)\ttotal: 2m 21s\tremaining: 11m 21s\n",
      "43:\ttest: 0.8728516\tbest: 0.8728516 (43)\ttotal: 2m 24s\tremaining: 11m 17s\n",
      "44:\ttest: 0.8728517\tbest: 0.8728517 (44)\ttotal: 2m 27s\tremaining: 11m 11s\n",
      "45:\ttest: 0.8728746\tbest: 0.8728746 (45)\ttotal: 2m 30s\tremaining: 11m 8s\n",
      "46:\ttest: 0.8729500\tbest: 0.8729500 (46)\ttotal: 2m 34s\tremaining: 11m 7s\n",
      "47:\ttest: 0.8729518\tbest: 0.8729518 (47)\ttotal: 2m 38s\tremaining: 11m 6s\n",
      "48:\ttest: 0.8729536\tbest: 0.8729536 (48)\ttotal: 2m 41s\tremaining: 11m 1s\n",
      "49:\ttest: 0.8729617\tbest: 0.8729617 (49)\ttotal: 2m 44s\tremaining: 10m 56s\n",
      "50:\ttest: 0.8730325\tbest: 0.8730325 (50)\ttotal: 2m 46s\tremaining: 10m 51s\n",
      "51:\ttest: 0.8730407\tbest: 0.8730407 (51)\ttotal: 2m 50s\tremaining: 10m 47s\n",
      "52:\ttest: 0.8730812\tbest: 0.8730812 (52)\ttotal: 2m 53s\tremaining: 10m 45s\n",
      "53:\ttest: 0.8730839\tbest: 0.8730839 (53)\ttotal: 2m 57s\tremaining: 10m 42s\n",
      "54:\ttest: 0.8730912\tbest: 0.8730912 (54)\ttotal: 3m\tremaining: 10m 40s\n",
      "55:\ttest: 0.8730915\tbest: 0.8730915 (55)\ttotal: 3m 3s\tremaining: 10m 34s\n",
      "56:\ttest: 0.8732430\tbest: 0.8732430 (56)\ttotal: 3m 6s\tremaining: 10m 31s\n",
      "57:\ttest: 0.8733006\tbest: 0.8733006 (57)\ttotal: 3m 10s\tremaining: 10m 30s\n",
      "58:\ttest: 0.8733008\tbest: 0.8733008 (58)\ttotal: 3m 13s\tremaining: 10m 26s\n",
      "59:\ttest: 0.8733233\tbest: 0.8733233 (59)\ttotal: 3m 16s\tremaining: 10m 21s\n",
      "60:\ttest: 0.8733280\tbest: 0.8733280 (60)\ttotal: 3m 19s\tremaining: 10m 17s\n",
      "61:\ttest: 0.8733692\tbest: 0.8733692 (61)\ttotal: 3m 22s\tremaining: 10m 13s\n",
      "62:\ttest: 0.8738875\tbest: 0.8738875 (62)\ttotal: 3m 26s\tremaining: 10m 11s\n",
      "63:\ttest: 0.8738933\tbest: 0.8738933 (63)\ttotal: 3m 29s\tremaining: 10m 7s\n",
      "64:\ttest: 0.8738945\tbest: 0.8738945 (64)\ttotal: 3m 32s\tremaining: 10m 4s\n",
      "65:\ttest: 0.8739567\tbest: 0.8739567 (65)\ttotal: 3m 35s\tremaining: 10m 2s\n",
      "66:\ttest: 0.8739912\tbest: 0.8739912 (66)\ttotal: 3m 39s\tremaining: 9m 58s\n",
      "67:\ttest: 0.8740026\tbest: 0.8740026 (67)\ttotal: 3m 42s\tremaining: 9m 56s\n",
      "68:\ttest: 0.8740241\tbest: 0.8740241 (68)\ttotal: 3m 46s\tremaining: 9m 53s\n",
      "69:\ttest: 0.8740591\tbest: 0.8740591 (69)\ttotal: 3m 49s\tremaining: 9m 50s\n",
      "70:\ttest: 0.8741049\tbest: 0.8741049 (70)\ttotal: 3m 53s\tremaining: 9m 47s\n",
      "71:\ttest: 0.8741080\tbest: 0.8741080 (71)\ttotal: 3m 56s\tremaining: 9m 45s\n",
      "72:\ttest: 0.8741874\tbest: 0.8741874 (72)\ttotal: 3m 59s\tremaining: 9m 41s\n",
      "73:\ttest: 0.8745477\tbest: 0.8745477 (73)\ttotal: 4m 3s\tremaining: 9m 38s\n",
      "74:\ttest: 0.8745534\tbest: 0.8745534 (74)\ttotal: 4m 5s\tremaining: 9m 33s\n",
      "75:\ttest: 0.8745746\tbest: 0.8745746 (75)\ttotal: 4m 8s\tremaining: 9m 29s\n",
      "76:\ttest: 0.8745937\tbest: 0.8745937 (76)\ttotal: 4m 11s\tremaining: 9m 25s\n",
      "77:\ttest: 0.8746000\tbest: 0.8746000 (77)\ttotal: 4m 14s\tremaining: 9m 21s\n",
      "78:\ttest: 0.8745967\tbest: 0.8746000 (77)\ttotal: 4m 17s\tremaining: 9m 17s\n",
      "79:\ttest: 0.8746220\tbest: 0.8746220 (79)\ttotal: 4m 21s\tremaining: 9m 15s\n",
      "80:\ttest: 0.8746342\tbest: 0.8746342 (80)\ttotal: 4m 25s\tremaining: 9m 13s\n",
      "81:\ttest: 0.8746406\tbest: 0.8746406 (81)\ttotal: 4m 28s\tremaining: 9m 10s\n",
      "82:\ttest: 0.8746410\tbest: 0.8746410 (82)\ttotal: 4m 31s\tremaining: 9m 5s\n",
      "83:\ttest: 0.8746523\tbest: 0.8746523 (83)\ttotal: 4m 34s\tremaining: 9m 2s\n",
      "84:\ttest: 0.8746620\tbest: 0.8746620 (84)\ttotal: 4m 38s\tremaining: 9m\n",
      "85:\ttest: 0.8747562\tbest: 0.8747562 (85)\ttotal: 4m 41s\tremaining: 8m 56s\n",
      "86:\ttest: 0.8749069\tbest: 0.8749069 (86)\ttotal: 4m 44s\tremaining: 8m 53s\n",
      "87:\ttest: 0.8749079\tbest: 0.8749079 (87)\ttotal: 4m 48s\tremaining: 8m 50s\n",
      "88:\ttest: 0.8749520\tbest: 0.8749520 (88)\ttotal: 4m 51s\tremaining: 8m 47s\n",
      "89:\ttest: 0.8749584\tbest: 0.8749584 (89)\ttotal: 4m 54s\tremaining: 8m 43s\n",
      "90:\ttest: 0.8749578\tbest: 0.8749584 (89)\ttotal: 4m 57s\tremaining: 8m 39s\n",
      "91:\ttest: 0.8749588\tbest: 0.8749588 (91)\ttotal: 5m\tremaining: 8m 36s\n",
      "92:\ttest: 0.8749935\tbest: 0.8749935 (92)\ttotal: 5m 4s\tremaining: 8m 33s\n",
      "93:\ttest: 0.8749857\tbest: 0.8749935 (92)\ttotal: 5m 7s\tremaining: 8m 30s\n",
      "94:\ttest: 0.8749874\tbest: 0.8749935 (92)\ttotal: 5m 10s\tremaining: 8m 26s\n",
      "95:\ttest: 0.8755539\tbest: 0.8755539 (95)\ttotal: 5m 13s\tremaining: 8m 23s\n",
      "96:\ttest: 0.8755830\tbest: 0.8755830 (96)\ttotal: 5m 16s\tremaining: 8m 18s\n",
      "97:\ttest: 0.8755828\tbest: 0.8755830 (96)\ttotal: 5m 19s\tremaining: 8m 15s\n",
      "98:\ttest: 0.8755831\tbest: 0.8755831 (98)\ttotal: 5m 21s\tremaining: 8m 10s\n",
      "99:\ttest: 0.8755934\tbest: 0.8755934 (99)\ttotal: 5m 24s\tremaining: 8m 7s\n",
      "100:\ttest: 0.8755990\tbest: 0.8755990 (100)\ttotal: 5m 27s\tremaining: 8m 3s\n",
      "101:\ttest: 0.8755992\tbest: 0.8755992 (101)\ttotal: 5m 30s\tremaining: 8m\n",
      "102:\ttest: 0.8755992\tbest: 0.8755992 (101)\ttotal: 5m 33s\tremaining: 7m 56s\n",
      "103:\ttest: 0.8756069\tbest: 0.8756069 (103)\ttotal: 5m 35s\tremaining: 7m 50s\n",
      "104:\ttest: 0.8756059\tbest: 0.8756069 (103)\ttotal: 5m 38s\tremaining: 7m 47s\n",
      "105:\ttest: 0.8757116\tbest: 0.8757116 (105)\ttotal: 5m 42s\tremaining: 7m 44s\n",
      "106:\ttest: 0.8756988\tbest: 0.8757116 (105)\ttotal: 5m 46s\tremaining: 7m 42s\n",
      "107:\ttest: 0.8757014\tbest: 0.8757116 (105)\ttotal: 5m 48s\tremaining: 7m 38s\n",
      "108:\ttest: 0.8757286\tbest: 0.8757286 (108)\ttotal: 5m 52s\tremaining: 7m 35s\n",
      "109:\ttest: 0.8758644\tbest: 0.8758644 (109)\ttotal: 5m 55s\tremaining: 7m 32s\n",
      "110:\ttest: 0.8759064\tbest: 0.8759064 (110)\ttotal: 5m 59s\tremaining: 7m 29s\n",
      "111:\ttest: 0.8758964\tbest: 0.8759064 (110)\ttotal: 6m 1s\tremaining: 7m 25s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112:\ttest: 0.8759059\tbest: 0.8759064 (110)\ttotal: 6m 4s\tremaining: 7m 22s\n",
      "113:\ttest: 0.8759130\tbest: 0.8759130 (113)\ttotal: 6m 7s\tremaining: 7m 18s\n",
      "114:\ttest: 0.8759088\tbest: 0.8759130 (113)\ttotal: 6m 10s\tremaining: 7m 15s\n",
      "115:\ttest: 0.8759734\tbest: 0.8759734 (115)\ttotal: 6m 14s\tremaining: 7m 12s\n",
      "116:\ttest: 0.8760216\tbest: 0.8760216 (116)\ttotal: 6m 18s\tremaining: 7m 9s\n",
      "117:\ttest: 0.8760213\tbest: 0.8760216 (116)\ttotal: 6m 21s\tremaining: 7m 6s\n",
      "118:\ttest: 0.8760227\tbest: 0.8760227 (118)\ttotal: 6m 24s\tremaining: 7m 3s\n",
      "119:\ttest: 0.8760249\tbest: 0.8760249 (119)\ttotal: 6m 28s\tremaining: 7m\n",
      "120:\ttest: 0.8760250\tbest: 0.8760250 (120)\ttotal: 6m 30s\tremaining: 6m 56s\n",
      "121:\ttest: 0.8760244\tbest: 0.8760250 (120)\ttotal: 6m 32s\tremaining: 6m 52s\n",
      "122:\ttest: 0.8760396\tbest: 0.8760396 (122)\ttotal: 6m 36s\tremaining: 6m 49s\n",
      "123:\ttest: 0.8760404\tbest: 0.8760404 (123)\ttotal: 6m 40s\tremaining: 6m 46s\n",
      "124:\ttest: 0.8760537\tbest: 0.8760537 (124)\ttotal: 6m 43s\tremaining: 6m 43s\n",
      "125:\ttest: 0.8761147\tbest: 0.8761147 (125)\ttotal: 6m 47s\tremaining: 6m 40s\n",
      "126:\ttest: 0.8761138\tbest: 0.8761147 (125)\ttotal: 6m 49s\tremaining: 6m 36s\n",
      "127:\ttest: 0.8761135\tbest: 0.8761147 (125)\ttotal: 6m 53s\tremaining: 6m 34s\n",
      "128:\ttest: 0.8761185\tbest: 0.8761185 (128)\ttotal: 6m 57s\tremaining: 6m 31s\n",
      "129:\ttest: 0.8761075\tbest: 0.8761185 (128)\ttotal: 6m 59s\tremaining: 6m 27s\n",
      "130:\ttest: 0.8761121\tbest: 0.8761185 (128)\ttotal: 7m 2s\tremaining: 6m 23s\n",
      "131:\ttest: 0.8761303\tbest: 0.8761303 (131)\ttotal: 7m 5s\tremaining: 6m 20s\n",
      "132:\ttest: 0.8761303\tbest: 0.8761303 (132)\ttotal: 7m 9s\tremaining: 6m 17s\n",
      "133:\ttest: 0.8761299\tbest: 0.8761303 (132)\ttotal: 7m 11s\tremaining: 6m 13s\n",
      "134:\ttest: 0.8761296\tbest: 0.8761303 (132)\ttotal: 7m 13s\tremaining: 6m 9s\n",
      "135:\ttest: 0.8762273\tbest: 0.8762273 (135)\ttotal: 7m 17s\tremaining: 6m 6s\n",
      "136:\ttest: 0.8762356\tbest: 0.8762356 (136)\ttotal: 7m 21s\tremaining: 6m 3s\n",
      "137:\ttest: 0.8762442\tbest: 0.8762442 (137)\ttotal: 7m 23s\tremaining: 6m\n",
      "138:\ttest: 0.8762441\tbest: 0.8762442 (137)\ttotal: 7m 26s\tremaining: 5m 56s\n",
      "139:\ttest: 0.8762433\tbest: 0.8762442 (137)\ttotal: 7m 30s\tremaining: 5m 53s\n",
      "140:\ttest: 0.8762430\tbest: 0.8762442 (137)\ttotal: 7m 33s\tremaining: 5m 50s\n",
      "141:\ttest: 0.8762650\tbest: 0.8762650 (141)\ttotal: 7m 36s\tremaining: 5m 47s\n",
      "142:\ttest: 0.8763690\tbest: 0.8763690 (142)\ttotal: 7m 40s\tremaining: 5m 44s\n",
      "143:\ttest: 0.8763716\tbest: 0.8763716 (143)\ttotal: 7m 43s\tremaining: 5m 41s\n",
      "144:\ttest: 0.8763992\tbest: 0.8763992 (144)\ttotal: 7m 46s\tremaining: 5m 38s\n",
      "145:\ttest: 0.8764002\tbest: 0.8764002 (145)\ttotal: 7m 49s\tremaining: 5m 34s\n",
      "146:\ttest: 0.8764029\tbest: 0.8764029 (146)\ttotal: 7m 52s\tremaining: 5m 31s\n",
      "147:\ttest: 0.8764029\tbest: 0.8764029 (147)\ttotal: 7m 55s\tremaining: 5m 27s\n",
      "148:\ttest: 0.8764057\tbest: 0.8764057 (148)\ttotal: 7m 58s\tremaining: 5m 24s\n",
      "149:\ttest: 0.8764058\tbest: 0.8764058 (149)\ttotal: 8m\tremaining: 5m 20s\n",
      "150:\ttest: 0.8764128\tbest: 0.8764128 (150)\ttotal: 8m 3s\tremaining: 5m 17s\n",
      "151:\ttest: 0.8764092\tbest: 0.8764128 (150)\ttotal: 8m 7s\tremaining: 5m 14s\n",
      "152:\ttest: 0.8764092\tbest: 0.8764128 (150)\ttotal: 8m 10s\tremaining: 5m 10s\n",
      "153:\ttest: 0.8764318\tbest: 0.8764318 (153)\ttotal: 8m 13s\tremaining: 5m 7s\n",
      "154:\ttest: 0.8764321\tbest: 0.8764321 (154)\ttotal: 8m 16s\tremaining: 5m 4s\n",
      "155:\ttest: 0.8764345\tbest: 0.8764345 (155)\ttotal: 8m 20s\tremaining: 5m 1s\n",
      "156:\ttest: 0.8764306\tbest: 0.8764345 (155)\ttotal: 8m 23s\tremaining: 4m 58s\n",
      "157:\ttest: 0.8764321\tbest: 0.8764345 (155)\ttotal: 8m 26s\tremaining: 4m 54s\n",
      "158:\ttest: 0.8764339\tbest: 0.8764345 (155)\ttotal: 8m 29s\tremaining: 4m 51s\n",
      "159:\ttest: 0.8764496\tbest: 0.8764496 (159)\ttotal: 8m 33s\tremaining: 4m 48s\n",
      "160:\ttest: 0.8764530\tbest: 0.8764530 (160)\ttotal: 8m 36s\tremaining: 4m 45s\n",
      "161:\ttest: 0.8766455\tbest: 0.8766455 (161)\ttotal: 8m 40s\tremaining: 4m 42s\n",
      "162:\ttest: 0.8766455\tbest: 0.8766455 (162)\ttotal: 8m 44s\tremaining: 4m 39s\n",
      "163:\ttest: 0.8766425\tbest: 0.8766455 (162)\ttotal: 8m 47s\tremaining: 4m 36s\n",
      "164:\ttest: 0.8766424\tbest: 0.8766455 (162)\ttotal: 8m 50s\tremaining: 4m 33s\n",
      "165:\ttest: 0.8766896\tbest: 0.8766896 (165)\ttotal: 8m 53s\tremaining: 4m 29s\n",
      "166:\ttest: 0.8767761\tbest: 0.8767761 (166)\ttotal: 8m 57s\tremaining: 4m 26s\n",
      "167:\ttest: 0.8769266\tbest: 0.8769266 (167)\ttotal: 9m\tremaining: 4m 23s\n",
      "168:\ttest: 0.8769267\tbest: 0.8769267 (168)\ttotal: 9m 3s\tremaining: 4m 20s\n",
      "169:\ttest: 0.8769283\tbest: 0.8769283 (169)\ttotal: 9m 5s\tremaining: 4m 16s\n",
      "170:\ttest: 0.8769275\tbest: 0.8769283 (169)\ttotal: 9m 9s\tremaining: 4m 13s\n",
      "171:\ttest: 0.8769272\tbest: 0.8769283 (169)\ttotal: 9m 11s\tremaining: 4m 10s\n",
      "172:\ttest: 0.8769283\tbest: 0.8769283 (172)\ttotal: 9m 14s\tremaining: 4m 6s\n",
      "173:\ttest: 0.8772686\tbest: 0.8772686 (173)\ttotal: 9m 18s\tremaining: 4m 3s\n",
      "174:\ttest: 0.8772686\tbest: 0.8772686 (174)\ttotal: 9m 20s\tremaining: 4m\n",
      "175:\ttest: 0.8773042\tbest: 0.8773042 (175)\ttotal: 9m 23s\tremaining: 3m 57s\n",
      "176:\ttest: 0.8775688\tbest: 0.8775688 (176)\ttotal: 9m 27s\tremaining: 3m 53s\n",
      "177:\ttest: 0.8775760\tbest: 0.8775760 (177)\ttotal: 9m 31s\tremaining: 3m 51s\n",
      "178:\ttest: 0.8775775\tbest: 0.8775775 (178)\ttotal: 9m 34s\tremaining: 3m 47s\n",
      "179:\ttest: 0.8775644\tbest: 0.8775775 (178)\ttotal: 9m 37s\tremaining: 3m 44s\n",
      "180:\ttest: 0.8775648\tbest: 0.8775775 (178)\ttotal: 9m 40s\tremaining: 3m 41s\n",
      "181:\ttest: 0.8775389\tbest: 0.8775775 (178)\ttotal: 9m 44s\tremaining: 3m 38s\n",
      "182:\ttest: 0.8775380\tbest: 0.8775775 (178)\ttotal: 9m 48s\tremaining: 3m 35s\n",
      "183:\ttest: 0.8778738\tbest: 0.8778738 (183)\ttotal: 9m 51s\tremaining: 3m 32s\n",
      "184:\ttest: 0.8778844\tbest: 0.8778844 (184)\ttotal: 9m 54s\tremaining: 3m 28s\n",
      "185:\ttest: 0.8779123\tbest: 0.8779123 (185)\ttotal: 9m 57s\tremaining: 3m 25s\n",
      "186:\ttest: 0.8779110\tbest: 0.8779123 (185)\ttotal: 10m 1s\tremaining: 3m 22s\n",
      "187:\ttest: 0.8779075\tbest: 0.8779123 (185)\ttotal: 10m 4s\tremaining: 3m 19s\n",
      "188:\ttest: 0.8779078\tbest: 0.8779123 (185)\ttotal: 10m 6s\tremaining: 3m 15s\n",
      "189:\ttest: 0.8779159\tbest: 0.8779159 (189)\ttotal: 10m 10s\tremaining: 3m 12s\n",
      "190:\ttest: 0.8779165\tbest: 0.8779165 (190)\ttotal: 10m 13s\tremaining: 3m 9s\n",
      "191:\ttest: 0.8779847\tbest: 0.8779847 (191)\ttotal: 10m 16s\tremaining: 3m 6s\n",
      "192:\ttest: 0.8779964\tbest: 0.8779964 (192)\ttotal: 10m 19s\tremaining: 3m 3s\n",
      "193:\ttest: 0.8779931\tbest: 0.8779964 (192)\ttotal: 10m 22s\tremaining: 2m 59s\n",
      "194:\ttest: 0.8779966\tbest: 0.8779966 (194)\ttotal: 10m 25s\tremaining: 2m 56s\n",
      "195:\ttest: 0.8779955\tbest: 0.8779966 (194)\ttotal: 10m 28s\tremaining: 2m 53s\n",
      "196:\ttest: 0.8780003\tbest: 0.8780003 (196)\ttotal: 10m 31s\tremaining: 2m 49s\n",
      "197:\ttest: 0.8780004\tbest: 0.8780004 (197)\ttotal: 10m 34s\tremaining: 2m 46s\n",
      "198:\ttest: 0.8779892\tbest: 0.8780004 (197)\ttotal: 10m 36s\tremaining: 2m 43s\n",
      "199:\ttest: 0.8779949\tbest: 0.8780004 (197)\ttotal: 10m 40s\tremaining: 2m 40s\n",
      "200:\ttest: 0.8780032\tbest: 0.8780032 (200)\ttotal: 10m 43s\tremaining: 2m 36s\n",
      "201:\ttest: 0.8780041\tbest: 0.8780041 (201)\ttotal: 10m 45s\tremaining: 2m 33s\n",
      "202:\ttest: 0.8780057\tbest: 0.8780057 (202)\ttotal: 10m 48s\tremaining: 2m 30s\n",
      "203:\ttest: 0.8780047\tbest: 0.8780057 (202)\ttotal: 10m 51s\tremaining: 2m 26s\n",
      "204:\ttest: 0.8780047\tbest: 0.8780057 (202)\ttotal: 10m 54s\tremaining: 2m 23s\n",
      "205:\ttest: 0.8780000\tbest: 0.8780057 (202)\ttotal: 10m 57s\tremaining: 2m 20s\n",
      "206:\ttest: 0.8780961\tbest: 0.8780961 (206)\ttotal: 11m\tremaining: 2m 17s\n",
      "207:\ttest: 0.8781030\tbest: 0.8781030 (207)\ttotal: 11m 3s\tremaining: 2m 14s\n",
      "208:\ttest: 0.8781028\tbest: 0.8781030 (207)\ttotal: 11m 7s\tremaining: 2m 10s\n",
      "209:\ttest: 0.8780777\tbest: 0.8781030 (207)\ttotal: 11m 11s\tremaining: 2m 7s\n",
      "210:\ttest: 0.8780834\tbest: 0.8781030 (207)\ttotal: 11m 15s\tremaining: 2m 4s\n",
      "211:\ttest: 0.8780972\tbest: 0.8781030 (207)\ttotal: 11m 18s\tremaining: 2m 1s\n",
      "212:\ttest: 0.8780974\tbest: 0.8781030 (207)\ttotal: 11m 21s\tremaining: 1m 58s\n",
      "213:\ttest: 0.8781018\tbest: 0.8781030 (207)\ttotal: 11m 24s\tremaining: 1m 55s\n",
      "214:\ttest: 0.8780994\tbest: 0.8781030 (207)\ttotal: 11m 28s\tremaining: 1m 52s\n",
      "215:\ttest: 0.8780998\tbest: 0.8781030 (207)\ttotal: 11m 31s\tremaining: 1m 48s\n",
      "216:\ttest: 0.8781432\tbest: 0.8781432 (216)\ttotal: 11m 35s\tremaining: 1m 45s\n",
      "217:\ttest: 0.8781399\tbest: 0.8781432 (216)\ttotal: 11m 39s\tremaining: 1m 42s\n",
      "218:\ttest: 0.8781398\tbest: 0.8781432 (216)\ttotal: 11m 42s\tremaining: 1m 39s\n",
      "219:\ttest: 0.8781403\tbest: 0.8781432 (216)\ttotal: 11m 44s\tremaining: 1m 36s\n",
      "220:\ttest: 0.8781407\tbest: 0.8781432 (216)\ttotal: 11m 47s\tremaining: 1m 32s\n",
      "221:\ttest: 0.8781404\tbest: 0.8781432 (216)\ttotal: 11m 49s\tremaining: 1m 29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222:\ttest: 0.8782709\tbest: 0.8782709 (222)\ttotal: 11m 53s\tremaining: 1m 26s\n",
      "223:\ttest: 0.8782690\tbest: 0.8782709 (222)\ttotal: 11m 55s\tremaining: 1m 23s\n",
      "224:\ttest: 0.8782704\tbest: 0.8782709 (222)\ttotal: 11m 58s\tremaining: 1m 19s\n",
      "225:\ttest: 0.8782727\tbest: 0.8782727 (225)\ttotal: 12m 2s\tremaining: 1m 16s\n",
      "226:\ttest: 0.8782770\tbest: 0.8782770 (226)\ttotal: 12m 5s\tremaining: 1m 13s\n",
      "227:\ttest: 0.8782772\tbest: 0.8782772 (227)\ttotal: 12m 8s\tremaining: 1m 10s\n",
      "228:\ttest: 0.8782784\tbest: 0.8782784 (228)\ttotal: 12m 10s\tremaining: 1m 7s\n",
      "229:\ttest: 0.8782864\tbest: 0.8782864 (229)\ttotal: 12m 14s\tremaining: 1m 3s\n",
      "230:\ttest: 0.8782904\tbest: 0.8782904 (230)\ttotal: 12m 17s\tremaining: 1m\n",
      "231:\ttest: 0.8782953\tbest: 0.8782953 (231)\ttotal: 12m 20s\tremaining: 57.5s\n",
      "232:\ttest: 0.8782988\tbest: 0.8782988 (232)\ttotal: 12m 24s\tremaining: 54.3s\n",
      "233:\ttest: 0.8782818\tbest: 0.8782988 (232)\ttotal: 12m 27s\tremaining: 51.1s\n",
      "234:\ttest: 0.8783737\tbest: 0.8783737 (234)\ttotal: 12m 30s\tremaining: 47.9s\n",
      "235:\ttest: 0.8783930\tbest: 0.8783930 (235)\ttotal: 12m 34s\tremaining: 44.7s\n",
      "236:\ttest: 0.8783975\tbest: 0.8783975 (236)\ttotal: 12m 36s\tremaining: 41.5s\n",
      "237:\ttest: 0.8784290\tbest: 0.8784290 (237)\ttotal: 12m 40s\tremaining: 38.3s\n",
      "238:\ttest: 0.8784227\tbest: 0.8784290 (237)\ttotal: 12m 43s\tremaining: 35.2s\n",
      "239:\ttest: 0.8784219\tbest: 0.8784290 (237)\ttotal: 12m 46s\tremaining: 31.9s\n",
      "240:\ttest: 0.8787911\tbest: 0.8787911 (240)\ttotal: 12m 49s\tremaining: 28.7s\n",
      "241:\ttest: 0.8787855\tbest: 0.8787911 (240)\ttotal: 12m 52s\tremaining: 25.5s\n",
      "242:\ttest: 0.8787870\tbest: 0.8787911 (240)\ttotal: 12m 54s\tremaining: 22.3s\n",
      "243:\ttest: 0.8787889\tbest: 0.8787911 (240)\ttotal: 12m 57s\tremaining: 19.1s\n",
      "244:\ttest: 0.8787749\tbest: 0.8787911 (240)\ttotal: 13m\tremaining: 15.9s\n",
      "245:\ttest: 0.8787717\tbest: 0.8787911 (240)\ttotal: 13m 4s\tremaining: 12.8s\n",
      "246:\ttest: 0.8787715\tbest: 0.8787911 (240)\ttotal: 13m 7s\tremaining: 9.56s\n",
      "247:\ttest: 0.8787893\tbest: 0.8787911 (240)\ttotal: 13m 10s\tremaining: 6.37s\n",
      "248:\ttest: 0.8787885\tbest: 0.8787911 (240)\ttotal: 13m 13s\tremaining: 3.19s\n",
      "249:\ttest: 0.8787946\tbest: 0.8787946 (249)\ttotal: 13m 16s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8787946342\n",
      "bestIteration = 249\n",
      "\n",
      "OOf score 0.13836876177210783\n"
     ]
    }
   ],
   "source": [
    "trn_data = Pool(val_train[features], label=val_train['target'],cat_features = cat_cols)\n",
    "\n",
    "clf = CatBoost(cat_params)\n",
    "clf.fit(trn_data,verbose_eval = True,eval_set=(trn_data))  \n",
    "predictions_cat = clf.predict(test[features],prediction_type='Probability')[:,1]\n",
    "oof_cat = clf.predict(val_train[features],prediction_type='Probability')[:,1]\n",
    "print ('OOf score', f1_score(val_train['target'], (oof_cat > 0.05).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOf score 0.13776419242525784\n"
     ]
    }
   ],
   "source": [
    "## Aveage the  two models for train\n",
    "print ('OOf score', f1_score(val_train['target'], ((0.5*oof_cat) + (0.5*oof_lgb) > 0.05).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Average two models for test\n",
    "predictions = (0.5*predictions_cat) + (0.5*predictions_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.995385\n",
       "1    0.004615\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_train['target'].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.994913\n",
       "1    0.005087\n",
       "Name: prediction, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred_prob'] = predictions\n",
    "# test['prediction'] = (test['pred_prob']>0.07).astype(int) ## Ensembling_07        LB:0.123049956178791      \n",
    "# test['prediction'] = (test['pred_prob']>0.06).astype(int) ## Ensembling_06        LB:0.12304120719675\n",
    "# test['prediction'] = (test['pred_prob']>0.05).astype(int) ## Ensembling_05        LB:\n",
    "test['prediction'] = (test['pred_prob']>0.065).astype(int) ## Ensembling_065       \n",
    "\n",
    "\n",
    "\n",
    "test['prediction'].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d9yRCR8bWXM6"
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['datetime x segment_id', 'prediction']].to_csv('Ensembling_065_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYxE7fFaW6Vr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174496, 45)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLbTuQ_x8c67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.994913\n",
       "1    0.005087\n",
       "Name: prediction, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.prediction.value_counts(True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Uber Movement Competition- Modelling - v1 (1).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "neptune": {
   "notebookId": "284bdfcb-40e5-4819-b3fd-58b709e39065"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
